# Explanatory file for Planck likelihood. The bounds are
# 4*sigma range of parameters (wrt Planck18)

# Usage:
#   python main.py sample planck_sample.yaml -v

output:
  # Output folder (str)
  path: output/planck/sample
  # Save incrementally or at the end (bool)
  # If True use num_processes: 1
  save_incrementally: True


# Sampling method for x.
# Options:
# - evaluate: evaluate the pipeline at a single point. It uses
#   the 'params:ref' key (otherwise this key is useless).
# - grid: uniform grid in the range ['params:min', 'params:max'];
# - log_grid: log grid in the range ['params:min', 'params:max'];
# - random_uniform: random uniform distribution in the range
#   ['params:min', 'params:max'];
# - random_normal: random normal distribution with mean 'params:loc'
#   and standard deviation 'params:scale';
# - latin_hypercube: random latin hypercube distribution. It is
#   possible to choose a seed to have deterministic results (see below);
# For a list of all available options look at src/emu_like/x_samplers.py.
x_sampler:
  # Name of the sampling (str).
  name: latin_hypercube
  # Arguments
  args:
    # Number of samples (int). Used in all but evaluate
    n_samples: 10
    # Seed (int). Used only in latin_hypercube to ensure
    # deterministic sampling
    seed: 12


# Function used to get y=f(x).
# Options:
# - linear_1d: y = a*x + b;
# - quadratic_1d: y = a*x^2 + b*x + c;
# - gaussian_1d: y = exp(-(x-mean^2)/std/2);
# - linear_2d: y = a*x1 + b*x2 + c
# - quadratic_2d: y = a*x1^2 + b*x2^2 + c*x1*x2 + d*x1 + e*x2 + f
# - cobaya_loglike: sample cobaya likelihoods
# - class_spectra: sample spectra generated by Class
# For a list of all available options look at src/emu_like/y_models.py.
y_model:
  # Name of the y_model (str).
  name: cobaya_loglike
  # Arguments
  args:
    theory:
      classy:
        extra_args:
          non_linear: hmcode
          N_ur: 2.0308
          N_ncdm: 1
          m_ncdm: 0.06
    likelihood:
      planck_2018_lowl.TT: null
      planck_2018_lowl.EE: null
  # List of output files (only for class_spectra)
  outputs:


# List of parameters.
params:
  # Samplers:
  # - evaluate: use 'params:ref'
  # - random_normal: use 'params:prior:loc' (mean), 'params:prior:scale' (std)
  # - all the others: use 'params:prior:min', 'params:prior:max'
  # Train generators:
  # - cobaya_loglike: write here parameters as in the cobaya 'params' block
  # - all the others: write here only the parameters that are varying
  #   (the fixed ones should go in 'train_generator:args')
  logA: # sampled parameter
    prior:
      min: 2.988
      max: 3.1
    ref: 3.0297862
    latex: \log(10^{10} A_\mathrm{s})
    drop: true
  A_s: # internal Class parameter
    value: 'lambda logA: 1e-10*np.exp(logA)'
    latex: A_\mathrm{s}
    derived: false
  n_s:
    prior:
      min: 0.9481
      max: 0.9817
    ref: 0.97084247
    latex: n_\mathrm{s}
  theta_s_1e2:
    prior:
      min: 1.03968
      max: 1.04216
    ref: 1.0410781
    latex: 100\theta_\mathrm{MC}
    drop: true
  100*theta_s:
    value: 'lambda theta_s_1e2: theta_s_1e2'
    derived: false
  omega_b:
    prior:
      min: 0.02177
      max: 0.02297
    ref: 0.022438922
    latex: \Omega_\mathrm{b} h^2
  omega_cdm:
    prior:
      min: 0.1152
      max: 0.1248
    ref: 0.11825479
    latex: \Omega_\mathrm{c} h^2
  tau_reio:
    prior:
      min: 0.0252
      max: 0.0836
    ref: 0.053234614
    latex: \tau_\mathrm{reio}
  A_planck:
    prior:
      min: 0.990839
      max: 1.0104
    ref: 1.0020416
