{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trivial example: linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rather trivial example, but it contains all necessary elements to train an emulator using Feed Forward Neural Networks alghorithms. In particular we are going to use Machine Learning to learn a linear relation of this type\n",
    "```\n",
    "y = a*x + b\n",
    "```\n",
    "where `a` and `b` are parameters and `x` is the unique feature.\n",
    "\n",
    "To do so, the main tasks will be:\n",
    "- generate a sample of data\n",
    "- build and train a simple architecture\n",
    "- test what the emulator learned.\n",
    "\n",
    "NOTE: this example contains enough documentation to learn the basics. In case, refer to `simple_sample.yaml`, `simple_train.yaml`, `planck_sample.yaml` and `planck_train.yaml` for additional information about the parameters to use and the possible choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and initialise relevant classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries: in this example we are first going to generate a sample (using the Sample class), and then build an emulator (using the FFNNEmu class). Here we are calling diectly the architecture we are going to use (instead of the base class Emulator), but it would be equivalent to call Emulator with a string specifying the type of emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 12:10:13.537227: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-30 12:10:13.539103: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-30 12:10:13.563776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-30 12:10:13.563806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-30 12:10:13.564445: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-30 12:10:13.568940: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-30 12:10:13.569421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-30 12:10:14.135651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from emu_like.sample import Sample\n",
    "from emu_like.ffnn_emu import FFNNEmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample()\n",
    "emu = FFNNEmu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dictionary of parameters. This should contain all the parameters that are needed by the function we are going to sample. In this example we are trying to fit a linear relation of the type\n",
    "```\n",
    "y = a*x + b\n",
    "```\n",
    "as defined in the `linear_1D` function in `src/emu_like/sampling_functions.py`.\n",
    "`x` is the variable we are going to vary, while `a` and `b` are fixed parameters.\n",
    "\n",
    "Each fixed parameter should have just a value, while for variables we need to specify\n",
    "a prior. The `prior` key should contain `min` and `max` parameters in most cases, except for gaussianly distributed priors, where it `loc` (mean) and `scale` (standard deviation) keys are expected.\n",
    "\n",
    "Defining a custom function is relatively simple: just add a new function to `src/emu_like/sampling_functions.py`, mimicking the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'x': {\n",
    "      'prior': {\n",
    "          'min': -1.,\n",
    "          'max': 4.,\n",
    "      },\n",
    "  },\n",
    "  'a': 2.,\n",
    "  'b': -1.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are generating the sample. On top of the previously described `params`, the `generate` method wants to know what is the function we are going to sample (`sampled_function`), the number of samples (`n_samples`) and the spacing (all the possibilities are described in `src/emu_like/samplers.py`). This method gives the possibility to incrementally save progresses (useful when the evaluation of the sampled_function takes some time). In case we want to use this option, it is necessary to specify an `output_path`, i.e. a folder that is going to store the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[info]\u001b[00m Generating sample.\n",
      "\u001b[1;32m----> \u001b[00mSampled function: linear_1d\n",
      "\u001b[1;32m----> \u001b[00mNumber of samples: 1000\n",
      "\u001b[1;32m----> \u001b[00mSpacing: grid\n",
      "\u001b[1;32m[info]\u001b[00m Initializing Grid sampler.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:00<00:00, 946917.45it/s]\n"
     ]
    }
   ],
   "source": [
    "sample.generate(\n",
    "    params,\n",
    "    sampled_function='linear_1d',\n",
    "    n_samples=1000,\n",
    "    spacing='grid',\n",
    "    save_incrementally=False,\n",
    "    output_path=None,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the sample is generated, we are going to randomly split it into train and test sample. We have to fix the fractional amount of data for the training sample and the random seed used for the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[info]\u001b[00m Splitting training and testing samples.\n",
      "\u001b[1;32m----> \u001b[00mFractional number of training samples: 0.9\n",
      "\u001b[1;32m----> \u001b[00mRandom seed for train/test split: 1543\n"
     ]
    }
   ],
   "source": [
    "sample.train_test_split(\n",
    "    frac_train=0.9,\n",
    "    seed=1543,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train more efficiently the emulator it is often useful to rescale both `x` and `y` to have them of order 1. The list of possible scalers can be found at `simple_train.yaml` (or in the source code at `src/emu_like/scalers.py`, where you can also add new scalers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[info]\u001b[00m Rescaling x and y.\n",
      "\u001b[1;32m----> \u001b[00mx with: StandardScaler\n",
      "\u001b[1;32m----> \u001b[00my with: MinMaxScalerPlus1\n",
      "\u001b[1;32m----> \u001b[00mRescaled bounds:\n",
      "\u001b[1;32m--------> \u001b[00mx_train_0 = [-1.7284147042373472, 1.7432962234401823]\n",
      "\u001b[1;32m--------> \u001b[00mx_test_0 = [-1.7179891458959733, 1.7328706650988084]\n",
      "\u001b[1;32m--------> \u001b[00my_train_0 = [1.0, 2.0]\n",
      "\u001b[1;32m--------> \u001b[00my_test_0 = [1.003003003003003, 1.9969969969969972]\n"
     ]
    }
   ],
   "source": [
    "sample.rescale(\n",
    "    rescale_x = 'StandardScaler',\n",
    "    rescale_y = 'MinMaxScalerPlus1',\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sample is generated, we have to build the emulator architecture and train it.\n",
    "Building the architecture consists in defining a set of parameters `params` and pass it to the `build` method. The parameters one should specify are listed below, and they are explained in depth in `simple_train.yaml` and `planck_train.yaml`.\n",
    "\n",
    "In particular, for linear regression a neural network can be very simple, i.e. without hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'activation': 'relu',\n",
    "    'neurons_hidden': [],\n",
    "    'batch_normalization': False,\n",
    "    'dropout_rate': 0.,\n",
    "    'optimizer': 'adam',\n",
    "    'loss': 'keras.losses.mean_squared_error',\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 32,\n",
    "    'want_output_layer': True,\n",
    "    'learning_rate': 1.e-3,\n",
    "    'sample_n_x': sample.n_x,\n",
    "    'sample_n_y': sample.n_y,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[info]\u001b[00m Building FFNN architecture\n",
      "\u001b[1;32m----> \u001b[00mActivation function: relu\n",
      "\u001b[1;32m----> \u001b[00mDropout rate: 0.0\n",
      "\u001b[1;32m----> \u001b[00mOptimizer: adam\n",
      "\u001b[1;32m----> \u001b[00mLoss function: keras.losses.mean_squared_error\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4 (16.00 Byte)\n",
      "Trainable params: 4 (16.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emu.build(\n",
    "    params,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to train the emulator. One has to pass a Sample object (already loaded, splitted into train and test samples and rescaled), the number of `epochs`, the `learning_rate` and the `batch_size`. It is possible also to save the emulator providing `path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1139 - val_loss: 1.0078\n",
      "Epoch 2/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0240 - val_loss: 0.9266\n",
      "Epoch 3/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.9502 - val_loss: 0.8624\n",
      "Epoch 4/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.8896 - val_loss: 0.8108\n",
      "Epoch 5/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.8401 - val_loss: 0.7678\n",
      "Epoch 6/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7976 - val_loss: 0.7275\n",
      "Epoch 7/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7573 - val_loss: 0.6901\n",
      "Epoch 8/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7201 - val_loss: 0.6540\n",
      "Epoch 9/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6839 - val_loss: 0.6192\n",
      "Epoch 10/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6480 - val_loss: 0.5860\n",
      "Epoch 11/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.5531\n",
      "Epoch 12/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5808 - val_loss: 0.5227\n",
      "Epoch 13/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5482 - val_loss: 0.4925\n",
      "Epoch 14/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.4636\n",
      "Epoch 15/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4873 - val_loss: 0.4361\n",
      "Epoch 16/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4098\n",
      "Epoch 17/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.3847\n",
      "Epoch 18/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3610\n",
      "Epoch 19/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3390\n",
      "Epoch 20/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3175\n",
      "Epoch 21/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.2962\n",
      "Epoch 22/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.2757\n",
      "Epoch 23/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.2571\n",
      "Epoch 24/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2613 - val_loss: 0.2376\n",
      "Epoch 25/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2405 - val_loss: 0.2198\n",
      "Epoch 26/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2213 - val_loss: 0.2021\n",
      "Epoch 27/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2027 - val_loss: 0.1851\n",
      "Epoch 28/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.1692\n",
      "Epoch 29/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1531\n",
      "Epoch 30/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1515 - val_loss: 0.1374\n",
      "Epoch 31/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1354 - val_loss: 0.1218\n",
      "Epoch 32/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1200 - val_loss: 0.1077\n",
      "Epoch 33/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1051 - val_loss: 0.0934\n",
      "Epoch 34/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0792\n",
      "Epoch 35/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0657\n",
      "Epoch 36/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0531\n",
      "Epoch 37/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0413\n",
      "Epoch 38/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0301\n",
      "Epoch 39/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0209\n",
      "Epoch 40/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 41/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 42/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 43/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 44/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 45/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.2141e-04 - val_loss: 6.2778e-04\n",
      "Epoch 46/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8033e-04 - val_loss: 3.3761e-04\n",
      "Epoch 47/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5541e-04 - val_loss: 1.8023e-04\n",
      "Epoch 48/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3484e-04 - val_loss: 9.2715e-05\n",
      "Epoch 49/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.8677e-05 - val_loss: 4.6878e-05\n",
      "Epoch 50/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4522e-05 - val_loss: 2.3132e-05\n",
      "Epoch 51/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7003e-05 - val_loss: 1.1404e-05\n",
      "Epoch 52/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2331e-06 - val_loss: 5.5228e-06\n",
      "Epoch 53/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9267e-06 - val_loss: 2.5719e-06\n",
      "Epoch 54/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8412e-06 - val_loss: 1.2065e-06\n",
      "Epoch 55/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.5965e-07 - val_loss: 5.5407e-07\n",
      "Epoch 56/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9335e-07 - val_loss: 2.5452e-07\n",
      "Epoch 57/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7685e-07 - val_loss: 1.1346e-07\n",
      "Epoch 58/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.8845e-08 - val_loss: 4.9508e-08\n",
      "Epoch 59/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3625e-08 - val_loss: 2.0901e-08\n",
      "Epoch 60/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4047e-08 - val_loss: 8.3844e-09\n",
      "Epoch 61/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.7168e-09 - val_loss: 3.4611e-09\n",
      "Epoch 62/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3516e-09 - val_loss: 1.3969e-09\n",
      "Epoch 63/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.2687e-10 - val_loss: 5.5017e-10\n",
      "Epoch 64/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6620e-10 - val_loss: 2.1592e-10\n",
      "Epoch 65/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4404e-10 - val_loss: 8.3583e-11\n",
      "Epoch 66/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3236e-11 - val_loss: 2.9669e-11\n",
      "Epoch 67/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0791e-11 - val_loss: 1.3682e-11\n",
      "Epoch 68/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0584e-11 - val_loss: 7.6969e-12\n",
      "Epoch 69/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7336e-12 - val_loss: 4.8490e-12\n",
      "Epoch 70/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9398e-12 - val_loss: 3.1386e-12\n",
      "Epoch 71/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.2628e-12 - val_loss: 3.1386e-12\n",
      "Epoch 72/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.2628e-12 - val_loss: 3.0940e-12\n",
      "Epoch 73/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.1054e-12 - val_loss: 2.8987e-12\n",
      "Epoch 74/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0214e-12 - val_loss: 2.8987e-12\n",
      "Epoch 75/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9571e-12 - val_loss: 2.7843e-12\n",
      "Epoch 76/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8998e-12 - val_loss: 2.7289e-12\n",
      "Epoch 77/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8378e-12 - val_loss: 2.6478e-12\n",
      "Epoch 78/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7351e-12 - val_loss: 2.6478e-12\n",
      "Epoch 79/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7351e-12 - val_loss: 2.6478e-12\n",
      "Epoch 80/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6659e-12 - val_loss: 2.5010e-12\n",
      "Epoch 81/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2459e-12 - val_loss: 2.0184e-12\n",
      "Epoch 82/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0853e-12 - val_loss: 2.0184e-12\n",
      "Epoch 83/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0853e-12 - val_loss: 2.0184e-12\n",
      "Epoch 84/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0853e-12 - val_loss: 2.0184e-12\n",
      "Epoch 85/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0853e-12 - val_loss: 2.0184e-12\n",
      "Epoch 86/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0853e-12 - val_loss: 2.0184e-12\n",
      "Epoch 87/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0404e-12 - val_loss: 1.9328e-12\n",
      "Epoch 88/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9789e-12 - val_loss: 1.9328e-12\n",
      "Epoch 89/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9789e-12 - val_loss: 1.9328e-12\n",
      "Epoch 90/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9545e-12 - val_loss: 1.7822e-12\n",
      "Epoch 91/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8506e-12 - val_loss: 1.7822e-12\n",
      "Epoch 92/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8506e-12 - val_loss: 1.7822e-12\n",
      "Epoch 93/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8497e-12 - val_loss: 1.6064e-12\n",
      "Epoch 94/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5880e-12 - val_loss: 1.5132e-12\n",
      "Epoch 95/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5649e-12 - val_loss: 1.3671e-12\n",
      "Epoch 96/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4341e-12 - val_loss: 1.3671e-12\n",
      "Epoch 97/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4341e-12 - val_loss: 1.3671e-12\n",
      "Epoch 98/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4341e-12 - val_loss: 1.3671e-12\n",
      "Epoch 99/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4341e-12 - val_loss: 1.3671e-12\n",
      "Epoch 100/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3575e-12 - val_loss: 1.3009e-12\n",
      "Epoch 101/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3499e-12 - val_loss: 1.3009e-12\n",
      "Epoch 102/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3499e-12 - val_loss: 1.3009e-12\n",
      "Epoch 103/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3473e-12 - val_loss: 1.2379e-12\n",
      "Epoch 104/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.8514e-13 - val_loss: 8.9386e-13\n",
      "Epoch 105/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.1718e-13 - val_loss: 8.9386e-13\n",
      "Epoch 106/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.1718e-13 - val_loss: 8.9386e-13\n",
      "Epoch 107/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.1718e-13 - val_loss: 8.9386e-13\n",
      "Epoch 108/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.1718e-13 - val_loss: 8.9386e-13\n",
      "Epoch 109/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.5016e-13 - val_loss: 8.1556e-13\n",
      "Epoch 110/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.4547e-13 - val_loss: 8.1556e-13\n",
      "Epoch 111/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.4547e-13 - val_loss: 8.1556e-13\n",
      "Epoch 112/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.4547e-13 - val_loss: 8.1556e-13\n",
      "Epoch 113/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.4547e-13 - val_loss: 7.5630e-13\n",
      "Epoch 114/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7835e-13 - val_loss: 7.5630e-13\n",
      "Epoch 115/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7835e-13 - val_loss: 7.5630e-13\n",
      "Epoch 116/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7835e-13 - val_loss: 7.5630e-13\n",
      "Epoch 117/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7835e-13 - val_loss: 7.5630e-13\n",
      "Epoch 118/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.4555e-13 - val_loss: 6.3793e-13\n",
      "Epoch 119/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.5743e-13 - val_loss: 6.3793e-13\n",
      "Epoch 120/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.5743e-13 - val_loss: 6.3793e-13\n",
      "Epoch 121/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.5743e-13 - val_loss: 6.1902e-13\n",
      "Epoch 122/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2075e-13 - val_loss: 5.9899e-13\n",
      "Epoch 123/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1964e-13 - val_loss: 5.9899e-13\n",
      "Epoch 124/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1964e-13 - val_loss: 5.9899e-13\n",
      "Epoch 125/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1964e-13 - val_loss: 5.9899e-13\n",
      "Epoch 126/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1964e-13 - val_loss: 5.9899e-13\n",
      "Epoch 127/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8659e-13 - val_loss: 5.4584e-13\n",
      "Epoch 128/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5317e-13 - val_loss: 5.3589e-13\n",
      "Epoch 129/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.2220e-13 - val_loss: 4.5475e-13\n",
      "Epoch 130/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6607e-13 - val_loss: 4.5475e-13\n",
      "Epoch 131/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6607e-13 - val_loss: 4.5475e-13\n",
      "Epoch 132/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6607e-13 - val_loss: 4.5475e-13\n",
      "Epoch 133/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6607e-13 - val_loss: 4.5475e-13\n",
      "Epoch 134/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6607e-13 - val_loss: 4.5475e-13\n",
      "Epoch 135/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6572e-13 - val_loss: 4.0387e-13\n",
      "Epoch 136/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 137/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 138/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 139/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 140/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 141/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 142/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1816e-13 - val_loss: 4.0387e-13\n",
      "Epoch 143/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8564e-13 - val_loss: 3.6479e-13\n",
      "Epoch 144/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7469e-13 - val_loss: 3.4333e-13\n",
      "Epoch 145/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5614e-13 - val_loss: 3.3182e-13\n",
      "Epoch 146/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4569e-13 - val_loss: 3.3182e-13\n",
      "Epoch 147/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4569e-13 - val_loss: 2.9004e-13\n",
      "Epoch 148/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7342e-13 - val_loss: 2.5850e-13\n",
      "Epoch 149/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6684e-13 - val_loss: 2.5352e-13\n",
      "Epoch 150/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5384e-13 - val_loss: 2.4073e-13\n",
      "Epoch 151/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 152/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 153/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 154/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 155/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 156/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 157/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.4073e-13\n",
      "Epoch 158/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4528e-13 - val_loss: 2.2510e-13\n",
      "Epoch 159/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.3393e-13 - val_loss: 2.2510e-13\n",
      "Epoch 160/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1030e-13 - val_loss: 1.9583e-13\n",
      "Epoch 161/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 162/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 163/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 164/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 165/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 166/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 167/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 168/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0153e-13 - val_loss: 1.9583e-13\n",
      "Epoch 169/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9965e-13 - val_loss: 1.4623e-13\n",
      "Epoch 170/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1901e-13 - val_loss: 1.1781e-13\n",
      "Epoch 171/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 172/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 173/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 174/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 175/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 176/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 177/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 178/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 179/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 180/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 181/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1797e-13 - val_loss: 1.1781e-13\n",
      "Epoch 182/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0938e-13 - val_loss: 7.9865e-14\n",
      "Epoch 183/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 184/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 185/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 186/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 187/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 188/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 189/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 190/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 191/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 192/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 193/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6123e-14 - val_loss: 7.9865e-14\n",
      "Epoch 194/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.0475e-14 - val_loss: 5.9828e-14\n",
      "Epoch 195/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 196/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 197/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 198/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 199/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 200/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 201/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 202/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 203/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 204/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 205/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.9828e-14\n",
      "Epoch 206/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6922e-14 - val_loss: 5.4428e-14\n",
      "Epoch 207/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3168e-14 - val_loss: 5.4428e-14\n",
      "Epoch 208/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7247e-14 - val_loss: 4.0785e-14\n",
      "Epoch 209/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 210/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 211/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 212/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 213/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 214/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 215/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 216/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 217/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 218/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 219/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 220/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 221/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7710e-14 - val_loss: 4.0785e-14\n",
      "Epoch 222/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4896e-14 - val_loss: 3.3396e-14\n",
      "Epoch 223/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4232e-14 - val_loss: 3.3396e-14\n",
      "Epoch 224/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5548e-14 - val_loss: 2.2169e-14\n",
      "Epoch 225/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3543e-14 - val_loss: 2.2169e-14\n",
      "Epoch 226/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3543e-14 - val_loss: 2.2169e-14\n",
      "Epoch 227/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3543e-14 - val_loss: 1.8048e-14\n",
      "Epoch 228/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 229/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 230/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 231/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 232/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 233/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 234/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 235/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 236/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 237/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 238/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 239/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 240/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 241/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 242/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 243/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 244/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 245/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 246/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0243e-14 - val_loss: 1.8048e-14\n",
      "Epoch 247/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3327e-14 - val_loss: 1.0658e-14\n",
      "Epoch 248/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 249/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 250/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 251/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 252/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 253/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 254/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 255/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 256/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 257/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 258/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 259/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 260/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 261/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 262/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 263/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 264/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 265/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 266/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 267/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 268/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 269/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 270/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 271/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 272/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0658e-14\n",
      "Epoch 273/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.7897e-15 - val_loss: 1.0232e-14\n",
      "Epoch 274/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.8739e-15 - val_loss: 1.0232e-14\n",
      "Epoch 275/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.0791e-15 - val_loss: 4.9738e-15\n",
      "Epoch 276/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 277/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 278/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 279/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 280/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 281/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 282/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 283/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 284/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 285/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 286/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 287/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 288/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 289/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 290/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 291/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 292/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 293/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 294/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 295/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 296/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 297/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 298/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 299/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 300/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 301/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7409e-15 - val_loss: 4.9738e-15\n",
      "Epoch 302/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5830e-15 - val_loss: 4.8317e-15\n",
      "Epoch 303/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 304/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 305/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 306/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 307/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 308/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 309/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 310/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 311/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 312/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 313/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 314/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 315/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 316/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 317/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 318/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 319/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 320/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 321/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 322/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 323/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 324/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 325/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 326/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 327/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 328/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 329/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 330/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0422e-15 - val_loss: 3.5527e-15\n",
      "Epoch 331/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 332/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 333/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 334/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 4.8317e-15\n",
      "Epoch 335/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 336/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 337/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 3.5527e-15\n",
      "Epoch 338/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 339/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 4.8317e-15\n",
      "Epoch 340/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 3.5527e-15\n",
      "Epoch 341/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 342/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9317e-15 - val_loss: 4.8317e-15\n",
      "Epoch 343/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9317e-15 - val_loss: 3.5527e-15\n",
      "Epoch 344/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 345/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0106e-15 - val_loss: 4.8317e-15\n",
      "Epoch 346/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9317e-15 - val_loss: 3.5527e-15\n",
      "Epoch 347/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9462e-15 - val_loss: 4.8317e-15\n",
      "Epoch 348/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0896e-15 - val_loss: 3.5527e-15\n",
      "Epoch 349/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7580e-15 - val_loss: 4.8317e-15\n",
      "Epoch 350/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8843e-15 - val_loss: 3.5527e-15\n",
      "Epoch 351/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6475e-15 - val_loss: 4.8317e-15\n",
      "Epoch 352/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6475e-15 - val_loss: 3.5527e-15\n",
      "Epoch 353/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9317e-15 - val_loss: 4.2633e-15\n",
      "Epoch 354/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0264e-15 - val_loss: 4.8317e-15\n",
      "Epoch 355/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8527e-15 - val_loss: 3.5527e-15\n",
      "Epoch 356/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0106e-15 - val_loss: 4.2633e-15\n",
      "Epoch 357/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0422e-15 - val_loss: 3.5527e-15\n",
      "Epoch 358/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3264e-15 - val_loss: 3.5527e-15\n",
      "Epoch 359/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0422e-15 - val_loss: 3.5527e-15\n",
      "Epoch 360/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7264e-15 - val_loss: 3.5527e-15\n",
      "Epoch 361/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6632e-15 - val_loss: 4.8317e-15\n",
      "Epoch 362/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9632e-15 - val_loss: 4.2633e-15\n",
      "Epoch 363/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5317e-15 - val_loss: 5.1159e-15\n",
      "Epoch 364/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8054e-15 - val_loss: 4.8317e-15\n",
      "Epoch 365/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8685e-15 - val_loss: 3.5527e-15\n",
      "Epoch 366/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1527e-15 - val_loss: 3.5527e-15\n",
      "Epoch 367/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4054e-15 - val_loss: 4.8317e-15\n",
      "Epoch 368/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6159e-15 - val_loss: 3.5527e-15\n",
      "Epoch 369/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8211e-15 - val_loss: 3.5527e-15\n",
      "Epoch 370/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9475e-15 - val_loss: 3.5527e-15\n",
      "Epoch 371/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8843e-15 - val_loss: 3.5527e-15\n",
      "Epoch 372/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1369e-15 - val_loss: 4.8317e-15\n",
      "Epoch 373/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0422e-15 - val_loss: 4.8317e-15\n",
      "Epoch 374/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5843e-15 - val_loss: 4.2633e-15\n",
      "Epoch 375/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9632e-15 - val_loss: 3.5527e-15\n",
      "Epoch 376/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0106e-15 - val_loss: 4.8317e-15\n",
      "Epoch 377/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3264e-15 - val_loss: 3.5527e-15\n",
      "Epoch 378/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6948e-15 - val_loss: 4.2633e-15\n",
      "Epoch 379/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7896e-15 - val_loss: 4.8317e-15\n",
      "Epoch 380/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6475e-15 - val_loss: 4.8317e-15\n",
      "Epoch 381/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.4159e-15 - val_loss: 8.6686e-15\n",
      "Epoch 382/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8580e-15 - val_loss: 4.2633e-15\n",
      "Epoch 383/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8738e-15 - val_loss: 4.8317e-15\n",
      "Epoch 384/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1211e-15 - val_loss: 6.6791e-15\n",
      "Epoch 385/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2475e-15 - val_loss: 4.8317e-15\n",
      "Epoch 386/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1054e-15 - val_loss: 3.5527e-15\n",
      "Epoch 387/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6580e-15 - val_loss: 4.2633e-15\n",
      "Epoch 388/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.1672e-15 - val_loss: 4.2633e-15\n",
      "Epoch 389/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1725e-15 - val_loss: 4.2633e-15\n",
      "Epoch 390/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2159e-15 - val_loss: 3.5527e-15\n",
      "Epoch 391/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1843e-15 - val_loss: 3.5527e-15\n",
      "Epoch 392/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6001e-15 - val_loss: 4.2633e-15\n",
      "Epoch 393/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7527e-15 - val_loss: 4.8317e-15\n",
      "Epoch 394/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4054e-15 - val_loss: 4.2633e-15\n",
      "Epoch 395/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9159e-15 - val_loss: 3.5527e-15\n",
      "Epoch 396/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9632e-15 - val_loss: 5.1159e-15\n",
      "Epoch 397/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8672e-15 - val_loss: 4.9738e-15\n",
      "Epoch 398/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5514e-15 - val_loss: 4.2633e-15\n",
      "Epoch 399/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3422e-15 - val_loss: 5.1159e-15\n",
      "Epoch 400/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.1949e-15 - val_loss: 4.8317e-15\n",
      "Epoch 401/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3738e-15 - val_loss: 4.2633e-15\n",
      "Epoch 402/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8527e-15 - val_loss: 5.1159e-15\n",
      "Epoch 403/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9422e-15 - val_loss: 4.8317e-15\n",
      "Epoch 404/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5159e-15 - val_loss: 7.6739e-15\n",
      "Epoch 405/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.9738e-15 - val_loss: 3.5527e-15\n",
      "Epoch 406/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1369e-15 - val_loss: 4.8317e-15\n",
      "Epoch 407/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8317e-15 - val_loss: 4.2633e-15\n",
      "Epoch 408/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6106e-15 - val_loss: 8.6686e-15\n",
      "Epoch 409/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7685e-15 - val_loss: 4.8317e-15\n",
      "Epoch 410/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7738e-15 - val_loss: 4.2633e-15\n",
      "Epoch 411/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7212e-15 - val_loss: 4.8317e-15\n",
      "Epoch 412/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2370e-15 - val_loss: 1.0374e-14\n",
      "Epoch 413/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8107e-15 - val_loss: 4.2633e-15\n",
      "Epoch 414/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6106e-15 - val_loss: 4.9738e-15\n",
      "Epoch 415/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9790e-15 - val_loss: 3.5527e-15\n",
      "Epoch 416/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4685e-15 - val_loss: 3.5527e-15\n",
      "Epoch 417/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4527e-15 - val_loss: 4.2633e-15\n",
      "Epoch 418/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9935e-15 - val_loss: 4.9738e-15\n",
      "Epoch 419/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4369e-15 - val_loss: 4.8317e-15\n",
      "Epoch 420/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4093e-15 - val_loss: 1.0658e-14\n",
      "Epoch 421/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.4580e-15 - val_loss: 9.0949e-15\n",
      "Epoch 422/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.4317e-15 - val_loss: 3.4106e-15\n",
      "Epoch 423/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3106e-15 - val_loss: 5.6843e-15\n",
      "Epoch 424/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6054e-15 - val_loss: 5.6843e-15\n",
      "Epoch 425/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7725e-15 - val_loss: 3.4106e-15\n",
      "Epoch 426/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5633e-15 - val_loss: 3.5527e-15\n",
      "Epoch 427/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9001e-15 - val_loss: 1.0090e-14\n",
      "Epoch 428/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2265e-15 - val_loss: 3.5527e-15\n",
      "Epoch 429/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0295e-14 - val_loss: 4.4054e-15\n",
      "Epoch 430/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8791e-15 - val_loss: 3.5527e-15\n",
      "Epoch 431/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9935e-15 - val_loss: 1.0090e-14\n",
      "Epoch 432/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0054e-15 - val_loss: 6.8212e-15\n",
      "Epoch 433/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3054e-15 - val_loss: 4.4054e-15\n",
      "Epoch 434/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5422e-15 - val_loss: 5.5422e-15\n",
      "Epoch 435/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.1528e-15 - val_loss: 6.2528e-15\n",
      "Epoch 436/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3528e-15 - val_loss: 3.8369e-15\n",
      "Epoch 437/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5527e-15 - val_loss: 3.8369e-15\n",
      "Epoch 438/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3738e-15 - val_loss: 3.8369e-15\n",
      "Epoch 439/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4843e-15 - val_loss: 1.3785e-14\n",
      "Epoch 440/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.8528e-15 - val_loss: 3.5527e-15\n",
      "Epoch 441/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2001e-15 - val_loss: 7.3896e-15\n",
      "Epoch 442/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.4001e-15 - val_loss: 9.6634e-15\n",
      "Epoch 443/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1580e-15 - val_loss: 1.0374e-14\n",
      "Epoch 444/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.6055e-15 - val_loss: 1.2790e-14\n",
      "Epoch 445/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.5213e-15 - val_loss: 1.5632e-14\n",
      "Epoch 446/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.7318e-15 - val_loss: 6.5370e-15\n",
      "Epoch 447/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7685e-15 - val_loss: 4.9738e-15\n",
      "Epoch 448/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8514e-15 - val_loss: 1.0090e-14\n",
      "Epoch 449/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.3528e-15 - val_loss: 1.0090e-14\n",
      "Epoch 450/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8107e-15 - val_loss: 4.4054e-15\n",
      "Epoch 451/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7423e-15 - val_loss: 1.0374e-14\n",
      "Epoch 452/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.6475e-15 - val_loss: 4.8317e-15\n",
      "Epoch 453/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5791e-15 - val_loss: 4.8317e-15\n",
      "Epoch 454/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6843e-15 - val_loss: 8.6686e-15\n",
      "Epoch 455/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.2106e-15 - val_loss: 5.2580e-15\n",
      "Epoch 456/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6054e-15 - val_loss: 8.1002e-15\n",
      "Epoch 457/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0423e-15 - val_loss: 4.9738e-15\n",
      "Epoch 458/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9896e-15 - val_loss: 9.2371e-15\n",
      "Epoch 459/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8146e-15 - val_loss: 8.5265e-15\n",
      "Epoch 460/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1700e-14 - val_loss: 1.2648e-14\n",
      "Epoch 461/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9896e-15 - val_loss: 5.1159e-15\n",
      "Epoch 462/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9528e-15 - val_loss: 7.2475e-15\n",
      "Epoch 463/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0311e-14 - val_loss: 1.6342e-14\n",
      "Epoch 464/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1416e-14 - val_loss: 2.6290e-14\n",
      "Epoch 465/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0874e-14 - val_loss: 1.0516e-14\n",
      "Epoch 466/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.8949e-15 - val_loss: 9.8055e-15\n",
      "Epoch 467/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1732e-14 - val_loss: 5.6843e-15\n",
      "Epoch 468/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.0528e-15 - val_loss: 1.5632e-14\n",
      "Epoch 469/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1637e-14 - val_loss: 4.4054e-15\n",
      "Epoch 470/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.8791e-15 - val_loss: 2.0464e-14\n",
      "Epoch 471/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5791e-15 - val_loss: 6.8212e-15\n",
      "Epoch 472/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7581e-15 - val_loss: 4.2633e-15\n",
      "Epoch 473/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5633e-15 - val_loss: 4.8317e-15\n",
      "Epoch 474/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1527e-15 - val_loss: 4.8317e-15\n",
      "Epoch 475/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.4633e-15 - val_loss: 3.5527e-15\n",
      "Epoch 476/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.6106e-15 - val_loss: 1.0090e-14\n",
      "Epoch 477/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4415e-14 - val_loss: 1.0800e-14\n",
      "Epoch 478/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2332e-14 - val_loss: 1.6911e-14\n",
      "Epoch 479/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1211e-14 - val_loss: 8.2423e-15\n",
      "Epoch 480/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1448e-14 - val_loss: 3.4817e-14\n",
      "Epoch 481/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.2101e-14 - val_loss: 8.5265e-15\n",
      "Epoch 482/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.7476e-15 - val_loss: 8.9528e-15\n",
      "Epoch 483/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3390e-14 - val_loss: 1.1653e-14\n",
      "Epoch 484/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1779e-14 - val_loss: 1.2363e-14\n",
      "Epoch 485/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0581e-15 - val_loss: 4.2633e-15\n",
      "Epoch 486/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.3423e-15 - val_loss: 9.2371e-15\n",
      "Epoch 487/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.2055e-15 - val_loss: 4.1211e-15\n",
      "Epoch 488/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0753e-14 - val_loss: 2.0748e-14\n",
      "Epoch 489/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4506e-14 - val_loss: 2.3732e-14\n",
      "Epoch 490/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6153e-14 - val_loss: 6.3949e-15\n",
      "Epoch 491/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3437e-14 - val_loss: 6.3949e-15\n",
      "Epoch 492/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.3160e-15 - val_loss: 9.0949e-15\n",
      "Epoch 493/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4783e-14 - val_loss: 5.8122e-14\n",
      "Epoch 494/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5869e-14 - val_loss: 4.9738e-15\n",
      "Epoch 495/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8916e-14 - val_loss: 9.2371e-15\n",
      "Epoch 496/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2742e-14 - val_loss: 1.1511e-14\n",
      "Epoch 497/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1748e-14 - val_loss: 1.1227e-14\n",
      "Epoch 498/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0406e-14 - val_loss: 1.5916e-14\n",
      "Epoch 499/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2806e-14 - val_loss: 5.4285e-14\n",
      "Epoch 500/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3580e-14 - val_loss: 8.7965e-14\n",
      "Epoch 501/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7054e-14 - val_loss: 8.8107e-15\n",
      "Epoch 502/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2048e-14 - val_loss: 6.9633e-15\n",
      "Epoch 503/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.5423e-15 - val_loss: 6.9633e-15\n",
      "Epoch 504/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6265e-15 - val_loss: 6.1675e-14\n",
      "Epoch 505/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2143e-14 - val_loss: 8.8107e-14\n",
      "Epoch 506/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5659e-14 - val_loss: 8.6686e-14\n",
      "Epoch 507/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.3100e-14 - val_loss: 2.0179e-14\n",
      "Epoch 508/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4621e-14 - val_loss: 4.0643e-14\n",
      "Epoch 509/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6799e-14 - val_loss: 6.6791e-15\n",
      "Epoch 510/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3306e-14 - val_loss: 5.7980e-14\n",
      "Epoch 511/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8327e-14 - val_loss: 3.9648e-14\n",
      "Epoch 512/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6752e-14 - val_loss: 3.3680e-14\n",
      "Epoch 513/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1969e-14 - val_loss: 7.3896e-15\n",
      "Epoch 514/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1669e-14 - val_loss: 1.2079e-14\n",
      "Epoch 515/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4369e-14 - val_loss: 6.1107e-15\n",
      "Epoch 516/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9917e-14 - val_loss: 3.9648e-14\n",
      "Epoch 517/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1827e-14 - val_loss: 7.5318e-15\n",
      "Epoch 518/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4179e-14 - val_loss: 1.2932e-14\n",
      "Epoch 519/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5928e-14 - val_loss: 7.6241e-13\n",
      "Epoch 520/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9727e-13 - val_loss: 9.4705e-12\n",
      "Epoch 521/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.2810e-12 - val_loss: 2.3022e-13\n",
      "Epoch 522/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4024e-13 - val_loss: 1.5044e-12\n",
      "Epoch 523/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1467e-13 - val_loss: 6.3665e-14\n",
      "Epoch 524/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.9560e-14 - val_loss: 2.8720e-13\n",
      "Epoch 525/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3660e-13 - val_loss: 2.6020e-13\n",
      "Epoch 526/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5158e-13 - val_loss: 2.7143e-14\n",
      "Epoch 527/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1467e-13 - val_loss: 8.2423e-15\n",
      "Epoch 528/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.1997e-14 - val_loss: 5.4712e-14\n",
      "Epoch 529/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.8844e-14 - val_loss: 3.1548e-14\n",
      "Epoch 530/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0601e-13 - val_loss: 1.2292e-13\n",
      "Epoch 531/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0426e-13 - val_loss: 7.3896e-15\n",
      "Epoch 532/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0591e-14 - val_loss: 2.6006e-14\n",
      "Epoch 533/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9591e-14 - val_loss: 9.0949e-15\n",
      "Epoch 534/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8622e-14 - val_loss: 4.3059e-14\n",
      "Epoch 535/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0664e-14 - val_loss: 1.5206e-14\n",
      "Epoch 536/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3464e-14 - val_loss: 1.7423e-13\n",
      "Epoch 537/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5170e-14 - val_loss: 2.4727e-14\n",
      "Epoch 538/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7581e-14 - val_loss: 7.8018e-14\n",
      "Epoch 539/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0612e-14 - val_loss: 1.3891e-12\n",
      "Epoch 540/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6352e-11 - val_loss: 2.8743e-11\n",
      "Epoch 541/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1258e-10 - val_loss: 8.1614e-09\n",
      "Epoch 542/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5342e-08 - val_loss: 1.6212e-07\n",
      "Epoch 543/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.9386e-08 - val_loss: 1.1796e-07\n",
      "Epoch 544/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8100e-08 - val_loss: 1.8938e-07\n",
      "Epoch 545/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3759e-07 - val_loss: 1.5381e-07\n",
      "Epoch 546/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.4475e-08 - val_loss: 2.5441e-08\n",
      "Epoch 547/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7602e-08 - val_loss: 1.7187e-08\n",
      "Epoch 548/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2138e-08 - val_loss: 3.2457e-09\n",
      "Epoch 549/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0182e-09 - val_loss: 9.3175e-10\n",
      "Epoch 550/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.1097e-10 - val_loss: 7.4316e-10\n",
      "Epoch 551/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9479e-10 - val_loss: 5.7939e-11\n",
      "Epoch 552/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8078e-11 - val_loss: 6.4433e-12\n",
      "Epoch 553/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0685e-11 - val_loss: 2.9293e-12\n",
      "Epoch 554/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1255e-12 - val_loss: 8.1045e-13\n",
      "Epoch 555/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2474e-12 - val_loss: 1.4192e-12\n",
      "Epoch 556/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1824e-12 - val_loss: 4.6451e-12\n",
      "Epoch 557/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3387e-12 - val_loss: 2.1900e-12\n",
      "Epoch 558/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9472e-13 - val_loss: 6.1107e-15\n",
      "Epoch 559/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6138e-14 - val_loss: 1.0985e-13\n",
      "Epoch 560/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.9228e-14 - val_loss: 5.0164e-14\n",
      "Epoch 561/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5122e-14 - val_loss: 1.1795e-14\n",
      "Epoch 562/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0406e-14 - val_loss: 2.9985e-14\n",
      "Epoch 563/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3459e-14 - val_loss: 1.3500e-14\n",
      "Epoch 564/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.9413e-14 - val_loss: 5.0449e-14\n",
      "Epoch 565/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0177e-13 - val_loss: 1.3927e-14\n",
      "Epoch 566/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0053e-14 - val_loss: 3.7090e-14\n",
      "Epoch 567/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5911e-14 - val_loss: 7.2760e-14\n",
      "Epoch 568/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 9.6665e-14 - val_loss: 5.6971e-13\n",
      "Epoch 569/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7778e-13 - val_loss: 1.8503e-13\n",
      "Epoch 570/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3276e-13 - val_loss: 1.7764e-14\n",
      "Epoch 571/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0038e-14 - val_loss: 6.3523e-14\n",
      "Epoch 572/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9935e-13 - val_loss: 1.7886e-12\n",
      "Epoch 573/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7067e-13 - val_loss: 4.2292e-13\n",
      "Epoch 574/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0468e-13 - val_loss: 1.9895e-14\n",
      "Epoch 575/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7487e-13 - val_loss: 9.6748e-13\n",
      "Epoch 576/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5216e-12 - val_loss: 5.2160e-12\n",
      "Epoch 577/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0683e-11 - val_loss: 1.2813e-09\n",
      "Epoch 578/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5011e-08 - val_loss: 8.5289e-07\n",
      "Epoch 579/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.2657e-07 - val_loss: 1.0606e-07\n",
      "Epoch 580/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1819e-07 - val_loss: 2.5321e-07\n",
      "Epoch 581/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5056e-08 - val_loss: 3.2782e-08\n",
      "Epoch 582/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7965e-09 - val_loss: 3.3685e-09\n",
      "Epoch 583/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.7871e-10 - val_loss: 7.0161e-11\n",
      "Epoch 584/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4442e-11 - val_loss: 1.4083e-12\n",
      "Epoch 585/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9663e-13 - val_loss: 2.7143e-14\n",
      "Epoch 586/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2390e-14 - val_loss: 3.0553e-14\n",
      "Epoch 587/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8668e-14 - val_loss: 8.2423e-15\n",
      "Epoch 588/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7795e-14 - val_loss: 4.2633e-15\n",
      "Epoch 589/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6453e-14 - val_loss: 1.0232e-14\n",
      "Epoch 590/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6780e-14 - val_loss: 3.2259e-14\n",
      "Epoch 591/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4896e-14 - val_loss: 1.3642e-14\n",
      "Epoch 592/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0385e-14 - val_loss: 2.0890e-14\n",
      "Epoch 593/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8895e-14 - val_loss: 4.1638e-14\n",
      "Epoch 594/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1916e-14 - val_loss: 2.2737e-14\n",
      "Epoch 595/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7085e-14 - val_loss: 1.4808e-13\n",
      "Epoch 596/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6774e-13 - val_loss: 2.1956e-13\n",
      "Epoch 597/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8028e-14 - val_loss: 4.8317e-14\n",
      "Epoch 598/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.3217e-14 - val_loss: 9.5639e-14\n",
      "Epoch 599/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1014e-13 - val_loss: 1.0417e-13\n",
      "Epoch 600/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3652e-13 - val_loss: 1.1833e-12\n",
      "Epoch 601/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.6647e-13 - val_loss: 1.2477e-13\n",
      "Epoch 602/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0439e-13 - val_loss: 1.6925e-13\n",
      "Epoch 603/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2795e-13 - val_loss: 6.5512e-14\n",
      "Epoch 604/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2575e-14 - val_loss: 2.6574e-14\n",
      "Epoch 605/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3273e-13 - val_loss: 8.3986e-14\n",
      "Epoch 606/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8346e-13 - val_loss: 5.4285e-14\n",
      "Epoch 607/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2245e-13 - val_loss: 2.2482e-13\n",
      "Epoch 608/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1492e-13 - val_loss: 3.2117e-14\n",
      "Epoch 609/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0260e-13 - val_loss: 3.4251e-12\n",
      "Epoch 610/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0884e-13 - val_loss: 5.6417e-14\n",
      "Epoch 611/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6557e-13 - val_loss: 5.8114e-12\n",
      "Epoch 612/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4071e-11 - val_loss: 7.0509e-12\n",
      "Epoch 613/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2219e-11 - val_loss: 2.2213e-11\n",
      "Epoch 614/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9741e-12 - val_loss: 2.3472e-12\n",
      "Epoch 615/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3660e-13 - val_loss: 1.5376e-13\n",
      "Epoch 616/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5005e-13 - val_loss: 1.5294e-12\n",
      "Epoch 617/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9854e-12 - val_loss: 6.4269e-12\n",
      "Epoch 618/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3868e-11 - val_loss: 2.5842e-10\n",
      "Epoch 619/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3223e-09 - val_loss: 4.3715e-09\n",
      "Epoch 620/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0508e-08 - val_loss: 3.5749e-08\n",
      "Epoch 621/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7491e-08 - val_loss: 3.2535e-08\n",
      "Epoch 622/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4884e-08 - val_loss: 4.1510e-08\n",
      "Epoch 623/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6366e-08 - val_loss: 5.8874e-08\n",
      "Epoch 624/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0416e-08 - val_loss: 1.0946e-07\n",
      "Epoch 625/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2301e-08 - val_loss: 4.9015e-08\n",
      "Epoch 626/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0937e-08 - val_loss: 3.4609e-08\n",
      "Epoch 627/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6994e-08 - val_loss: 2.1530e-07\n",
      "Epoch 628/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.2133e-07 - val_loss: 1.9637e-08\n",
      "Epoch 629/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8322e-08 - val_loss: 1.6499e-08\n",
      "Epoch 630/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4832e-08 - val_loss: 2.2385e-08\n",
      "Epoch 631/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5897e-09 - val_loss: 3.2049e-09\n",
      "Epoch 632/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6915e-09 - val_loss: 1.3550e-09\n",
      "Epoch 633/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9605e-10 - val_loss: 9.9797e-11\n",
      "Epoch 634/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.6028e-11 - val_loss: 1.1863e-10\n",
      "Epoch 635/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8008e-11 - val_loss: 4.9123e-12\n",
      "Epoch 636/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.5106e-12 - val_loss: 2.3074e-11\n",
      "Epoch 637/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0163e-11 - val_loss: 4.9010e-12\n",
      "Epoch 638/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7498e-11 - val_loss: 1.7822e-11\n",
      "Epoch 639/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8979e-11 - val_loss: 4.2436e-12\n",
      "Epoch 640/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4725e-12 - val_loss: 1.0134e-12\n",
      "Epoch 641/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9080e-13 - val_loss: 5.6090e-13\n",
      "Epoch 642/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2954e-13 - val_loss: 7.2191e-14\n",
      "Epoch 643/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.2781e-14 - val_loss: 6.3949e-15\n",
      "Epoch 644/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1474e-14 - val_loss: 3.0838e-14\n",
      "Epoch 645/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3285e-14 - val_loss: 1.2363e-14\n",
      "Epoch 646/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6890e-14 - val_loss: 2.0890e-14\n",
      "Epoch 647/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7345e-13 - val_loss: 3.3253e-14\n",
      "Epoch 648/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.2679e-13 - val_loss: 3.8710e-13\n",
      "Epoch 649/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3634e-13 - val_loss: 1.7053e-13\n",
      "Epoch 650/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0490e-13 - val_loss: 1.8417e-13\n",
      "Epoch 651/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.5761e-13 - val_loss: 3.0198e-13\n",
      "Epoch 652/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.8628e-14 - val_loss: 7.5033e-14\n",
      "Epoch 653/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4453e-14 - val_loss: 9.2371e-15\n",
      "Epoch 654/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0672e-13 - val_loss: 3.7943e-14\n",
      "Epoch 655/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.2485e-13 - val_loss: 5.2715e-12\n",
      "Epoch 656/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5898e-11 - val_loss: 1.7399e-11\n",
      "Epoch 657/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1898e-11 - val_loss: 1.6663e-11\n",
      "Epoch 658/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0756e-10 - val_loss: 1.7168e-08\n",
      "Epoch 659/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9230e-08 - val_loss: 1.1050e-07\n",
      "Epoch 660/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0399e-07 - val_loss: 3.8383e-08\n",
      "Epoch 661/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6118e-08 - val_loss: 4.0138e-08\n",
      "Epoch 662/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1069e-08 - val_loss: 6.3474e-09\n",
      "Epoch 663/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9866e-09 - val_loss: 7.9331e-10\n",
      "Epoch 664/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9831e-10 - val_loss: 8.0849e-10\n",
      "Epoch 665/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0101e-10 - val_loss: 1.2086e-10\n",
      "Epoch 666/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7129e-10 - val_loss: 2.2464e-10\n",
      "Epoch 667/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2802e-10 - val_loss: 5.5348e-11\n",
      "Epoch 668/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0718e-11 - val_loss: 6.4574e-12\n",
      "Epoch 669/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.3858e-11 - val_loss: 8.2659e-12\n",
      "Epoch 670/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0171e-11 - val_loss: 3.0431e-12\n",
      "Epoch 671/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3844e-12 - val_loss: 5.2376e-12\n",
      "Epoch 672/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8988e-12 - val_loss: 8.9761e-12\n",
      "Epoch 673/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8226e-12 - val_loss: 3.3722e-13\n",
      "Epoch 674/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3287e-11 - val_loss: 8.2561e-12\n",
      "Epoch 675/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2436e-11 - val_loss: 5.6763e-11\n",
      "Epoch 676/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6121e-11 - val_loss: 3.3602e-11\n",
      "Epoch 677/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6851e-10 - val_loss: 5.1150e-09\n",
      "Epoch 678/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0130e-09 - val_loss: 1.1708e-10\n",
      "Epoch 679/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4753e-10 - val_loss: 7.3433e-10\n",
      "Epoch 680/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0976e-10 - val_loss: 3.4529e-10\n",
      "Epoch 681/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2996e-10 - val_loss: 3.6098e-10\n",
      "Epoch 682/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3204e-10 - val_loss: 1.8168e-09\n",
      "Epoch 683/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7340e-09 - val_loss: 1.3230e-08\n",
      "Epoch 684/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.3550e-09 - val_loss: 2.5911e-08\n",
      "Epoch 685/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0130e-07 - val_loss: 2.4328e-07\n",
      "Epoch 686/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2580e-07 - val_loss: 1.0834e-07\n",
      "Epoch 687/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3958e-08 - val_loss: 3.0603e-09\n",
      "Epoch 688/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5437e-09 - val_loss: 1.6441e-10\n",
      "Epoch 689/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.0003e-10 - val_loss: 1.2510e-09\n",
      "Epoch 690/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8930e-10 - val_loss: 7.1531e-10\n",
      "Epoch 691/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2516e-10 - val_loss: 5.5979e-11\n",
      "Epoch 692/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4762e-11 - val_loss: 4.5975e-12\n",
      "Epoch 693/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7856e-12 - val_loss: 1.3078e-12\n",
      "Epoch 694/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7478e-13 - val_loss: 5.4712e-14\n",
      "Epoch 695/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2938e-14 - val_loss: 9.1646e-13\n",
      "Epoch 696/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6216e-13 - val_loss: 8.6970e-14\n",
      "Epoch 697/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.6302e-14 - val_loss: 2.2169e-14\n",
      "Epoch 698/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6775e-14 - val_loss: 1.2221e-14\n",
      "Epoch 699/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3753e-14 - val_loss: 5.4001e-15\n",
      "Epoch 700/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4357e-14 - val_loss: 9.1802e-14\n",
      "Epoch 701/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0448e-13 - val_loss: 6.7558e-13\n",
      "Epoch 702/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7004e-13 - val_loss: 1.6200e-14\n",
      "Epoch 703/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4564e-14 - val_loss: 3.9222e-14\n",
      "Epoch 704/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4427e-14 - val_loss: 3.1122e-14\n",
      "Epoch 705/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7132e-14 - val_loss: 5.1159e-15\n",
      "Epoch 706/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5101e-14 - val_loss: 7.4181e-14\n",
      "Epoch 707/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 7.0517e-14 - val_loss: 1.1937e-14\n",
      "Epoch 708/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6312e-14 - val_loss: 6.8781e-14\n",
      "Epoch 709/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.4323e-14 - val_loss: 1.9156e-13\n",
      "Epoch 710/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0021e-13 - val_loss: 7.1324e-13\n",
      "Epoch 711/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5030e-13 - val_loss: 2.4869e-13\n",
      "Epoch 712/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5753e-13 - val_loss: 9.0992e-13\n",
      "Epoch 713/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.3505e-12 - val_loss: 1.1241e-11\n",
      "Epoch 714/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9415e-12 - val_loss: 6.9983e-12\n",
      "Epoch 715/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3505e-11 - val_loss: 1.0960e-11\n",
      "Epoch 716/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.3899e-12 - val_loss: 5.3475e-13\n",
      "Epoch 717/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0110e-13 - val_loss: 1.2648e-14\n",
      "Epoch 718/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.0507e-14 - val_loss: 1.2932e-14\n",
      "Epoch 719/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.5116e-13 - val_loss: 1.0942e-14\n",
      "Epoch 720/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5292e-13 - val_loss: 5.1772e-12\n",
      "Epoch 721/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3673e-11 - val_loss: 8.1342e-12\n",
      "Epoch 722/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0910e-10 - val_loss: 1.1910e-09\n",
      "Epoch 723/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0017e-08 - val_loss: 6.7797e-07\n",
      "Epoch 724/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6371e-07 - val_loss: 2.3600e-07\n",
      "Epoch 725/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.5430e-08 - val_loss: 7.1296e-08\n",
      "Epoch 726/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1564e-08 - val_loss: 2.9875e-09\n",
      "Epoch 727/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4135e-08 - val_loss: 1.4773e-10\n",
      "Epoch 728/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.0870e-10 - val_loss: 9.1964e-10\n",
      "Epoch 729/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1078e-10 - val_loss: 3.6320e-11\n",
      "Epoch 730/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7898e-11 - val_loss: 1.0230e-11\n",
      "Epoch 731/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5305e-12 - val_loss: 2.1458e-14\n",
      "Epoch 732/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9849e-14 - val_loss: 2.3604e-13\n",
      "Epoch 733/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2890e-14 - val_loss: 9.6634e-15\n",
      "Epoch 734/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.3042e-14 - val_loss: 9.9476e-15\n",
      "Epoch 735/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5301e-14 - val_loss: 4.9312e-14\n",
      "Epoch 736/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.3949e-14 - val_loss: 1.3742e-13\n",
      "Epoch 737/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4601e-14 - val_loss: 2.9274e-14\n",
      "Epoch 738/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2490e-14 - val_loss: 2.9416e-14\n",
      "Epoch 739/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9374e-14 - val_loss: 6.3949e-14\n",
      "Epoch 740/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5585e-14 - val_loss: 6.3807e-14\n",
      "Epoch 741/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.0026e-14 - val_loss: 2.4443e-14\n",
      "Epoch 742/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5216e-14 - val_loss: 6.6791e-15\n",
      "Epoch 743/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7222e-14 - val_loss: 1.5632e-13\n",
      "Epoch 744/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1527e-13 - val_loss: 1.3770e-13\n",
      "Epoch 745/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.3238e-14 - val_loss: 6.5796e-14\n",
      "Epoch 746/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4059e-14 - val_loss: 1.8574e-13\n",
      "Epoch 747/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.1298e-13 - val_loss: 1.8332e-14\n",
      "Epoch 748/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6617e-14 - val_loss: 1.2264e-13\n",
      "Epoch 749/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5136e-13 - val_loss: 1.0658e-14\n",
      "Epoch 750/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1034e-13 - val_loss: 5.8407e-13\n",
      "Epoch 751/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.1662e-13 - val_loss: 5.3291e-13\n",
      "Epoch 752/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.8104e-13 - val_loss: 1.0421e-12\n",
      "Epoch 753/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9594e-13 - val_loss: 8.4270e-14\n",
      "Epoch 754/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.1949e-14 - val_loss: 1.3287e-13\n",
      "Epoch 755/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1722e-14 - val_loss: 1.6314e-13\n",
      "Epoch 756/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7291e-13 - val_loss: 2.9985e-13\n",
      "Epoch 757/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3591e-13 - val_loss: 5.9916e-12\n",
      "Epoch 758/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5387e-12 - val_loss: 2.4301e-13\n",
      "Epoch 759/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0002e-12 - val_loss: 3.5158e-13\n",
      "Epoch 760/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1597e-12 - val_loss: 2.5466e-13\n",
      "Epoch 761/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.7976e-13 - val_loss: 1.5731e-13\n",
      "Epoch 762/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7547e-12 - val_loss: 3.9796e-12\n",
      "Epoch 763/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7264e-11 - val_loss: 1.1399e-10\n",
      "Epoch 764/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9276e-10 - val_loss: 5.4420e-10\n",
      "Epoch 765/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4612e-08 - val_loss: 1.2555e-08\n",
      "Epoch 766/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1058e-08 - val_loss: 2.6299e-09\n",
      "Epoch 767/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.4649e-08 - val_loss: 3.8855e-09\n",
      "Epoch 768/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0137e-07 - val_loss: 6.8248e-07\n",
      "Epoch 769/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9466e-07 - val_loss: 8.1666e-08\n",
      "Epoch 770/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3043e-08 - val_loss: 6.7239e-09\n",
      "Epoch 771/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1210e-09 - val_loss: 5.8058e-10\n",
      "Epoch 772/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4536e-10 - val_loss: 7.6456e-11\n",
      "Epoch 773/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.6249e-11 - val_loss: 2.0593e-10\n",
      "Epoch 774/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.1508e-10 - val_loss: 1.5634e-10\n",
      "Epoch 775/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6793e-10 - val_loss: 2.2254e-10\n",
      "Epoch 776/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5775e-10 - val_loss: 1.6942e-10\n",
      "Epoch 777/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9920e-11 - val_loss: 6.0919e-12\n",
      "Epoch 778/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0796e-12 - val_loss: 2.0258e-12\n",
      "Epoch 779/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5571e-12 - val_loss: 8.9244e-14\n",
      "Epoch 780/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1417e-13 - val_loss: 6.8496e-14\n",
      "Epoch 781/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.8776e-14 - val_loss: 8.5407e-14\n",
      "Epoch 782/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.6349e-14 - val_loss: 2.1600e-14\n",
      "Epoch 783/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3874e-14 - val_loss: 1.2363e-14\n",
      "Epoch 784/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3601e-13 - val_loss: 1.7668e-12\n",
      "Epoch 785/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8568e-12 - val_loss: 1.4978e-13\n",
      "Epoch 786/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0565e-13 - val_loss: 1.2581e-12\n",
      "Epoch 787/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3149e-12 - val_loss: 1.3895e-11\n",
      "Epoch 788/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2555e-12 - val_loss: 2.7138e-12\n",
      "Epoch 789/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5221e-12 - val_loss: 1.8227e-11\n",
      "Epoch 790/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.7700e-11 - val_loss: 1.4411e-10\n",
      "Epoch 791/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.3906e-10 - val_loss: 5.1361e-10\n",
      "Epoch 792/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9860e-09 - val_loss: 5.1272e-09\n",
      "Epoch 793/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2952e-09 - val_loss: 1.1690e-10\n",
      "Epoch 794/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.1659e-10 - val_loss: 8.7181e-09\n",
      "Epoch 795/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6492e-09 - val_loss: 1.8212e-09\n",
      "Epoch 796/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3897e-08 - val_loss: 5.6108e-08\n",
      "Epoch 797/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7869e-07 - val_loss: 9.9881e-09\n",
      "Epoch 798/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3890e-08 - val_loss: 5.0772e-08\n",
      "Epoch 799/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.1087e-09 - val_loss: 1.2688e-09\n",
      "Epoch 800/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6082e-10 - val_loss: 1.5481e-10\n",
      "Epoch 801/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7492e-11 - val_loss: 4.5385e-12\n",
      "Epoch 802/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.4282e-12 - val_loss: 4.0345e-13\n",
      "Epoch 803/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.1236e-13 - val_loss: 5.5707e-14\n",
      "Epoch 804/1000\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 9.1107e-14 - val_loss: 4.3215e-13\n",
      "Epoch 805/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0770e-14 - val_loss: 1.0658e-13\n",
      "Epoch 806/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8458e-14 - val_loss: 6.4233e-14\n",
      "Epoch 807/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2573e-14 - val_loss: 3.9833e-13\n",
      "Epoch 808/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4429e-13 - val_loss: 3.5698e-13\n",
      "Epoch 809/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.5455e-13 - val_loss: 3.4333e-13\n",
      "Epoch 810/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.7150e-13 - val_loss: 2.0350e-13\n",
      "Epoch 811/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1383e-13 - val_loss: 3.1363e-13\n",
      "Epoch 812/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8722e-13 - val_loss: 1.3856e-13\n",
      "Epoch 813/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.8007e-14 - val_loss: 1.6485e-14\n",
      "Epoch 814/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.9129e-14 - val_loss: 4.0373e-13\n",
      "Epoch 815/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5899e-13 - val_loss: 2.6105e-13\n",
      "Epoch 816/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2486e-14 - val_loss: 6.4517e-14\n",
      "Epoch 817/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6622e-14 - val_loss: 1.7337e-14\n",
      "Epoch 818/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6137e-14 - val_loss: 9.5213e-14\n",
      "Epoch 819/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.3023e-14 - val_loss: 8.0576e-14\n",
      "Epoch 820/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.1675e-14 - val_loss: 8.8249e-14\n",
      "Epoch 821/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.8270e-14 - val_loss: 1.2705e-13\n",
      "Epoch 822/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.4186e-14 - val_loss: 3.4106e-14\n",
      "Epoch 823/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.6113e-14 - val_loss: 5.1870e-14\n",
      "Epoch 824/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6309e-13 - val_loss: 4.3130e-13\n",
      "Epoch 825/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2170e-14 - val_loss: 1.0118e-13\n",
      "Epoch 826/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.2054e-13 - val_loss: 2.7327e-13\n",
      "Epoch 827/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.4396e-13 - val_loss: 1.1958e-12\n",
      "Epoch 828/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9113e-12 - val_loss: 3.8595e-12\n",
      "Epoch 829/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2344e-12 - val_loss: 1.5974e-12\n",
      "Epoch 830/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0217e-12 - val_loss: 1.7778e-12\n",
      "Epoch 831/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7967e-12 - val_loss: 4.3160e-12\n",
      "Epoch 832/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3526e-11 - val_loss: 3.5531e-11\n",
      "Epoch 833/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.5431e-10 - val_loss: 3.5739e-10\n",
      "Epoch 834/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.0274e-08 - val_loss: 2.3149e-07\n",
      "Epoch 835/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.8759e-07 - val_loss: 2.9620e-07\n",
      "Epoch 836/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9928e-07 - val_loss: 8.9355e-08\n",
      "Epoch 837/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2788e-07 - val_loss: 1.8246e-07\n",
      "Epoch 838/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0507e-07 - val_loss: 2.0794e-08\n",
      "Epoch 839/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7826e-08 - val_loss: 4.9912e-09\n",
      "Epoch 840/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1139e-09 - val_loss: 7.6397e-11\n",
      "Epoch 841/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6721e-11 - val_loss: 1.6539e-12\n",
      "Epoch 842/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0323e-11 - val_loss: 3.0747e-12\n",
      "Epoch 843/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6223e-12 - val_loss: 1.2700e-12\n",
      "Epoch 844/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.8272e-13 - val_loss: 7.0443e-13\n",
      "Epoch 845/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6066e-13 - val_loss: 2.3107e-13\n",
      "Epoch 846/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0390e-14 - val_loss: 8.3844e-15\n",
      "Epoch 847/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1400e-14 - val_loss: 1.4495e-14\n",
      "Epoch 848/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.2711e-14 - val_loss: 5.4001e-15\n",
      "Epoch 849/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1732e-14 - val_loss: 1.4069e-14\n",
      "Epoch 850/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8348e-14 - val_loss: 1.6200e-14\n",
      "Epoch 851/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9027e-14 - val_loss: 8.8107e-15\n",
      "Epoch 852/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.1032e-14 - val_loss: 2.5011e-14\n",
      "Epoch 853/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0499e-14 - val_loss: 2.4727e-14\n",
      "Epoch 854/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9516e-14 - val_loss: 2.6716e-14\n",
      "Epoch 855/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.4685e-14 - val_loss: 1.0374e-14\n",
      "Epoch 856/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.1148e-14 - val_loss: 1.7195e-14\n",
      "Epoch 857/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.6974e-14 - val_loss: 9.3792e-15\n",
      "Epoch 858/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.8585e-14 - val_loss: 8.9528e-15\n",
      "Epoch 859/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.0881e-13 - val_loss: 3.2415e-13\n",
      "Epoch 860/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3012e-13 - val_loss: 1.2477e-13\n",
      "Epoch 861/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.3222e-14 - val_loss: 3.4532e-14\n",
      "Epoch 862/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.1643e-14 - val_loss: 1.4921e-14\n",
      "Epoch 863/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5506e-14 - val_loss: 5.1159e-15\n",
      "Epoch 864/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3116e-14 - val_loss: 2.7569e-14\n",
      "Epoch 865/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9912e-14 - val_loss: 1.5007e-13\n",
      "Epoch 866/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.3036e-13 - val_loss: 6.6791e-15\n",
      "Epoch 867/1000\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.4952e-14 - val_loss: 2.5580e-14\n",
      "Epoch 868/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.0444e-14 - val_loss: 2.7285e-14\n",
      "Epoch 869/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.4786e-14 - val_loss: 6.1249e-14\n",
      "Epoch 870/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9380e-14 - val_loss: 1.0942e-14\n",
      "Epoch 871/1000\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2469e-14 - val_loss: 2.9274e-14\n",
      "Epoch 872/1000\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8422e-14"
     ]
    }
   ],
   "source": [
    "emu.train(\n",
    "    sample,\n",
    "    epochs=1000,\n",
    "    learning_rate=1.e-3,\n",
    "    batch_size=32,\n",
    "    path=None,\n",
    "    get_plot=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the evolution of the loss function per epoch, evaluated for the training sample and the validation sample. It is possible to notice that the loss function starts high and then decreases, reaching a plateau. After that both samples start scattering. This indicates that the learning rate could be decreased. However, since the accuracy reached is good enough we just stop the emulator and use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we are going to evaluate the emulator on the sample points, and then we plot the input `y` against the emulated ones. In the last plot, where we show the relative differences, it is possible to notice that the relative difference is noticeable only when the curves are passing through zero (an artifact of dividing by zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emu = np.array([emu.eval(x) for x in sample.x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82fd6558d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sample.x[:,0], sample.y[:,0], s=0.1, label='sample')\n",
    "plt.scatter(sample.x[:,0], y_emu[:,0], s=0.1, label='emulated')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAGzCAYAAAAhXWNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA64UlEQVR4nO3dfXSU9Z3//9fcZCbkFkJIQiAItooNlARDCLTVokYp7YKwa8txexNxi62/lGpjW+HX7xdqa6vn0PJLldmiu6uopxbWriBKK2oqxa0oMRiEACoWJRATCJEkMyGZzM3vD5o0QEgyycxcc/N8nDPnNFeuXNc7qcm8+Hzen89l8vv9fgEAAMQ5s9EFAAAARAJCEQAAgAhFAAAAkghFAAAAkghFAAAAkghFAAAAkghFAAAAkghFAAAAkghFAAAAkghFAAAAkiSr0QVEC5/Pp4aGBqWmpspkMhldDgAAGAK/36/29nbl5ubKbB54LCiuQtGZM2dUWloqj8cjj8eju+66S8uXLx/S1zY0NCgvLy/EFQIAgFCor6/XxIkTBzzHFE8PhPV6verq6lJSUpJcLpemT5+ut956S2PHjh30a1tbWzV69GjV19crLS0tDNUCAICRamtrU15ens6cOaP09PQBz42rkSKLxaKkpCRJUldXl/x+v4aaCXumzNLS0ghFAABEmaG0vkRVo/WuXbu0cOFC5ebmymQyaevWrRed43A4NHnyZCUmJqqkpER79uw57/NnzpxRQUGBJk6cqB/96EfKzMwMU/UAACCSRVUocrlcKigokMPh6PfzmzdvVkVFhdasWaO9e/eqoKBA8+fP18mTJ3vPGT16tPbt26ejR4/q6aefVlNTU7/X6urqUltb23kvAAAQu6IqFC1YsED333+/lixZ0u/n161bp+XLl2vZsmXKz8/Xhg0blJSUpMcee+yic7Ozs1VQUKDXXnut32s98MADSk9P733RZA0AQGyLqlA0ELfbrZqaGpWWlvYeM5vNKi0t1e7duyVJTU1Nam9vl3SucXrXrl2aOnVqv9dbtWqVWltbe1/19fWh/yYAAIBhYqbRurm5WV6vV9nZ2ecdz87O1uHDhyVJH330ke64447eBusVK1bos5/9bL/Xs9vtstvtIa8bAABEhpgJRUMxe/Zs1dbWBvQ1DodDDodDXq83NEUBAICIEDPTZ5mZmbJYLBc1Tjc1NSknJ2fY1y0vL9fBgwdVXV090hIBAEAEi5lQZLPZVFRUpKqqqt5jPp9PVVVVmjt3roGVAQCAaBBV02dOp1NHjhzp/fjo0aOqra1VRkaGJk2apIqKCpWVlWnWrFmaPXu2Kisr5XK5tGzZsmHfk+kzAADiQ1Q95mPnzp267rrrLjpeVlamjRs3SpLWr1+vtWvXqrGxUYWFhXrooYdUUlIy4nu3tbUpPT1dra2t7GgNAECUCOT9O6pCkZEIRQAARJ9A3r9jpqcIAABgJAhFg3A4HMrPz1dxcbHRpQAAgBBi+myImD6DETrcHu2oa9T8aTlKskXVuggAiAhMnwExYkddo1qcbr1U1/+DiwEAwUMoAiLY/Gk5Gpti103Tsgc/GQAwIoSiQdBTBCMl2axaPHMCU2cAEAb0FA0RPUUAAEQfeooAAAACRCgCAAAQoQgAAEASoWhQNFoDABAfaLQeIhqtAQCIPjRaAwAABIhQBAAAIEIRAACAJEIRAACAJELRoFh9BgBAfGD12RCx+gwAgOjD6jMAAIAAEYoAAABEKAIAAJBEKAIAAJBEKAIAAJBEKAIAAJBEKBoU+xQBABAf2KdoiNinCEbocHu0o65R86flKMlmNbocAIg67FMExIgddY1qcbr1Ul2T0aUAQMwjFAERbP60HI1NseumadlGlwIAMY/xeCCCJdmsWjxzgtFlAEBcYKQIAABAhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhKJB8ZgPAADiA4/5GCIe8wEAQPThMR8AAAABIhQBAACIUAQAACCJUAQAACCJUAQAACCJUAREvA63R1vePq4Ot8foUgAgphGKgAi3o65RLU63XqprMroUAIhphCIgws2flqOxKXbdNC3b6FIAIKZZjS4AwMCSbFYtnjnB6DIAIOYxUgQAACBCEQAAgKQ4C0X19fWaN2+e8vPzNWPGDD3zzDNGlwQMiJVnABA+cRWKrFarKisrdfDgQb300ku6++675XK5jC4LuCRWngFA+MRVKBo/frwKCwslSTk5OcrMzFRLS4uxRQEDYOUZAIRPVIWiXbt2aeHChcrNzZXJZNLWrVsvOsfhcGjy5MlKTExUSUmJ9uzZ0++1ampq5PV6lZeXF+KqgeHrWXmWZGOhKACEWlSFIpfLpYKCAjkcjn4/v3nzZlVUVGjNmjXau3evCgoKNH/+fJ08efK881paWvStb31Ljz766CXv1dXVpba2tvNeAAAgdpn8fr/f6CKGw2QyacuWLVq8eHHvsZKSEhUXF2v9+vWSJJ/Pp7y8PK1YsUIrV66UdC7s3HjjjVq+fLm++c1vXvL6P/3pT3XfffdddLy1tVVpaWnB/WYAAEBItLW1KT09fUjv31E1UjQQt9utmpoalZaW9h4zm80qLS3V7t27JUl+v1+33Xabrr/++gEDkSStWrVKra2tva/6+vqQ1g8AAIwVM6GoublZXq9X2dnnN6RmZ2ersbFRkvTXv/5Vmzdv1tatW1VYWKjCwkLt37+/3+vZ7XalpaWd9wIAALErrro3v/CFL8jn8wX0NQ6HQw6HQ16vN0RVAQCASBAzI0WZmZmyWCxqajp/P5empibl5OQM+7rl5eU6ePCgqqurR1oiMCxs4AgA4REzochms6moqEhVVVW9x3w+n6qqqjR37lwDKwNGhg0cASA8omr6zOl06siRI70fHz16VLW1tcrIyNCkSZNUUVGhsrIyzZo1S7Nnz1ZlZaVcLpeWLVs27HsyfQajzZ+Wo5fqmtjAEQBCLKqW5O/cuVPXXXfdRcfLysq0ceNGSdL69eu1du1aNTY2qrCwUA899JBKSkpGfO9AlvQBAIDIEMj7d1SFIiMRihBuHW6PdtQ1av60HHa0BoBhist9ioBYQy8RAIQXoWgQDodD+fn5Ki4uNroUxBkeBgsA4cX02RAxfQYAQPRh+gwAACBAhCIAAAARigZFTxEiAbtaA0Do0VM0RPQUwUhb3j6uFqdbY1PsWjxzgtHlAEDUoKcIiAF9R4dYiQYAoUcoAiJU332KkmxWLZ45gU0cASCECEVAhGJ0CADCi1A0CBqtYRRGhwAgvGi0HiIarQEAiD40WgMxhiX5ABB6hCIgCvBwWAAIPUIREIEuHBmi6RoAQo9QBESgC0eGaLoGgNAjFA2C1WcwAiNDABB+rD4bIlafAQAQfVh9BsQgVqABQGgRioAI1F8AYgUaAIQWoQiIQP0FIPqMACC0CEVABOovALECDQBCi7+uQATqCUAAgPBhpAiIMJdqqKbRGgBCi1A0CPYpQrhdqqGaRmsACC32KRoi9ilCuHS4PXqprkk3Tcs+r3/oUscBAJcWyPs3f1mBCOTXxf9Woc8IAEKL6TMgwgw0TUZfEQCEDqEIiDAD7UdEXxEAhA6hCIgwA+1HxAaOABA6hCIgggw2PcYGjgAQOoQiIIIMNj1GTxEAhA6hCIgg11yRqaPNLn3hirH9fp6eIgAIHUIREEFee79ZUzKT9b/vn+738/QUAUDoEIqACDKU0NPfHkYAgJEjFA2Cx3wgXDrcHu2oaxxwx2qmzwAgdHjMxxDxmA+E2pa3j6vF6dbYFPsld67mUR8AEJhA3r8ZKQIixGBN1tK5Jfk3TcvWjrpGVqABQJARioAIMViTdQ+m0AAgNAhFQIQYykhRIOcBAAJDKAIixFBHioZ6HgAgMIQiIAJ0uD3q8niVkmgddA8i9ioCgNAgFAERYEddo1ydXtmtlkFXldFsDQChQSgCIkCgfUI0WwNA8BGKgAgQaJ8QzdYAEHyEIsBggfQT9aDZGgCCj1AEGGzbvgbt/qBFkoa8S/X8aTlKSbSq0+OlrwgAgoRQBBjOL1OAX5Fks8pmNcvV6aGvCACCJO5C0ZIlSzRmzBjdcsstRpcC9I7yzP3UWC0syA3oa+krAoDgirtQdNddd+nJJ580ugxA0vCmznrQVwQAwRV3oWjevHlKTU01ugxAHW6P3v7oE3l9/mF9PX1FABBcURWKdu3apYULFyo3N1cmk0lbt2696ByHw6HJkycrMTFRJSUl2rNnT/gLBYZg274GObs8SrFbAp46k+grAoBgi6pQ5HK5VFBQIIfD0e/nN2/erIqKCq1Zs0Z79+5VQUGB5s+fr5MnTwZ8r66uLrW1tZ33AoLLrwSLWTMnjQl46qwHfUUAEDxRFYoWLFig+++/X0uWLOn38+vWrdPy5cu1bNky5efna8OGDUpKStJjjz0W8L0eeOABpaen977y8vJGWj7QayQN1n3RVwQAwRNVoWggbrdbNTU1Ki0t7T1mNptVWlqq3bt3B3y9VatWqbW1tfdVX18fzHIR50bSYN0XfUUAEDzD/2scYZqbm+X1epWdff6OwNnZ2Tp8+HDvx6Wlpdq3b59cLpcmTpyoZ555RnPnzr3oena7XXa7PeR1Iz65PT7Vt3TIfdmYEV0nyWaVX37tPtIik6SlxZOCUyAAxKGYCUVD9corrwR0vsPhkMPhkNfrDVFFiDcdbo/qTrQqd/Qo2azBGKw1yRTo7o8AgIvEzPRZZmamLBaLmprOX4XT1NSknJycYV+3vLxcBw8eVHV19UhLBCSNfNXZhUo/k6UUu1U3fCYrCNUBQPyKmVBks9lUVFSkqqqq3mM+n09VVVX9To8BRmh2dmrL3hPy+f0jWnXW12vvN2vC6FGqfPl9+ooAYASiKhQ5nU7V1taqtrZWknT06FHV1tbq2LFjkqSKigr9x3/8h5544gkdOnRId955p1wul5YtWzbsezocDuXn56u4uDgY3wLiWIfbo+//vlaJCWa1nfUEZZRIOtdsfeLMWU0YM4r9igBgBEx+v3942+kaYOfOnbruuusuOl5WVqaNGzdKktavX6+1a9eqsbFRhYWFeuihh1RSUjLie7e1tSk9PV2tra1KS0sb8fUQfzZVH9Orh5vUetaj9f86U5kpiUG7drOzU5Uvv6+7b7wiqNcFgGgXyPt3VIUiIxGKMBIdbo/u21Ynl9ura67IDPoqsS1vH1fjmU6dOHNW/+9XPhOUaTkAiAWBvH9H1fQZEK3+UFOvw43tSrSagzZt1tf8aTn66LRLZ8669fy+hqBfHwDiAaFoEPQUYaQ63B5tf6dR3V6frGZTSEZxkmxWFV42RvJLe499QsM1AAwD02dDxPQZhqPD7dF9z9ep2eWWqzP4vUQX3uuX2w9pwphRGp8+SotnTgjJfQAgmjB9BkSIbfsadPjjdp1ud2vJzAkhbYJOsll1941X6MQnZ3lALAAMA6EICJGePYmy0uy6KiclJL1EF2LPIgAYPkLRIOgpwnA0Ozt166NvKsFiUkeXV6sXTgvLijAargFg+AhFg+AxHwhUTyDKTLGpqa1Lv7m1MGxL5Gm4BoDhIxQBQdTh9qj8d3sl+XWqvUu/v6Mk7JspLirIVYrdKleXh9EiAAhAQP98/dnPfhbQxefNm6drr702oK8BolXPSrP2To+6PH4tv2aKIbtLJ9msyp+QrufePiG3xxf2+wNAtAooFLF6H+hfTyCqa2iTxWzW5z6Vrn8pmmhYPTarWePTE3WgoVUdbg87XAPAELBP0SAcDoccDoe8Xq/ee+899inCRfoGIpNMmpabGrbG6oFq+tm2OjndHl1zxbigP1YEAKIF+xQFEY3WGEizs1PLHt+juhOtEROIJBquAWA4ghqK6uvrdfvttwfzkkDEanZ2aukju/XhaZfOnO2OmEDUg4ZrAAhMUENRS0uLnnjiiWBeEohIPcvuTZI8Xr/mTBkbUYFIYrQIAAIV0F/wbdu2Dfj5v/3tbyMqBoh0HW6P/lBTryde/1BZqYk62d6lu0uv1L8UTYyoQNRjUUGuaj/6RM6/jxbRWwQAlxbQX/HFixfLZDINuArNZDKNuCggEnW4Pfq/W/dr57unNCYpQc1OtzZ/Z44hy+6Hqme06H/fO6W9xz7RwoLciAxvABAJApo+Gz9+vJ599ln5fL5+X3v37g1VnYbhMR/ocHv05O6jKvuvN/XG307LajFJMhmyMeNwLCrIVaLVrHcb2/U/NceNLgcAIlZAoaioqEg1NTWX/Pxgo0jRiNVn8a1nddl/7Pqb6j85K5PJpCmZKdoU4SNEfSXZrLJYzXJ3+7T9nQZ6iwDgEgIKRT/60Y/0uc997pKf//SnP61XX311xEUBRutwe/Sfr32gL//mNTW73PJLystI0neu/ZQeu604agJRjx/Nn6rUUQkanWxjJRoAXAKbNw5RIJs/IXr1NFI/X9ugD065ZDFJJrNJK66/ImKbqYdqU/Ux/e97p5ScaNWaCFspBwChEsj7N38VAZ0LQ0+/+ZF+98YxdXt98vj8SrSZlZRg1ePLipWXkWx0iSPGSjQAGBihCHHtwpGhbq9PCRaTPpWVqkUFuVE/OtRXz0q0nYeb9Oze47rhM1lRNw0IAKEUG3/tgQA1Ozv1wPZDOnrapVPtXer2nhsZGm1N0NdLLtOtJZNiJgz1taggV9tqG5SYYNH3f1+r/yybFZPfJwAMx4j/Gr733nu6/PLLZbXyhxWRrWdUqObDFtUeb9WZjm7J71fqqATlZSTF3MhQf5JsVj10a6HKf/e2xiQnMI0GAH2M+K//Zz7zGR06dEhXXnllMOqJOA6HQw6HQ16v1+hSMEz1LS79YPM+dXu9anG51d7pld/vk8Vs0pRxqVo8c0LMh6G+MlMSteTqCUyjAcAFRrz6zGw26/DhwzEbinqw+iy69EyPdXZ7tOfDM+r0+OTx+jQ2xaas1ERNGjNKRZMz4ioM9dXh9mjZ49Vq7+zWjAnpevCWAqNLAoCQYPUZ4lJPEHJ2dWvvsVaZzSa1d3qUYjcr0WpSyRVZKrl8bNwGob6SbFZ9ZUaOnqk+rg9OudTs7GS0CEDci+93BkS9nqmxsckJeq/JqU6PV6edbtktUqLNquuvzFSizaqVX76KN/0L3FKUpxcPNCnBYqLpGgBEKEKU6TstJql3aqyr26uM5ASNsll1/dRxauno1q+/VhAT+wuFSt+m69RRVt33fB2bOgKIa/z1Q0TrG4I8Pv9502KSeqfGPv+pcUqxJzAiFKCeputNbx5Tc3sXq9EAxDVCESJG3yXznr/vKt03BHm8vvOmxSQxNRYEiwpy9faxT3Ta5WY1GoC4RiiCYS4cBTrc6JTX55ezyyu313dRCPL4/EyLhUCS7dyz0M6tRvPoVy++y2o0AHFpxKHo3nvv1dixY4NRC2JUfyNAja1dOtPZLbfHp9az50aBzCa/kmxWXT4uRblpdkJQGLEaDQCCsE9RvGCfoqHpuxrMaj537PiZTtW3nJXX71e31y+P1ye//EpKsCgjxa5pOany+Pw65XTry58dH7OP2Ih0HW6Pvv3EW0qwmNTt9bMaDUBMCOT9m1A0RISif+i7H1Bja5dy0hN7A1Df1WBWy7mDfr9fdotJo5Ntmj4+7dxIUVuXJmcm6//802cYkYggzc7O3tVoY5NtrEYDEPXYvDGI4vUxH/2N+Fw47XXa6ZZffh1qbO8NQH1Xg1lNpt7r0RAdHViNBiCeMVI0RLE0UnRhj4/0j8DTM+rT34jPhdNeU7NS1NjWpZx0e28AIvxEvw63R/c9X6fTLrfaz3bL8fWr+f8TQNQK+/TZk08+2e/xb33rWyO9dMSIllB04eaGF4Yd6eIeH+kfgcckk6wWs1LsZvn9UtFlY3oDD9Ne8aOnv8hskprauvT7O0r4/xtAVAr79Nn+/ft7/3dXV5defvllzZgxI6ZCkZE63B49/eZH2v7Ox8pKtV80ndU38Bz4uF1nOrrV7fFJJlNv2Ok7xdXT4zPm7z0+vdfqM+rDiE9869nteukjbyjBYmKZPoC4EJRQtHbt2vM+djqdWrx4cTAuHRcuHN2Rzg88p5xd+rC5Qx3dXtU1tF00ndU38CSYJYvZpCnZqZo4OvGisNOD0IPBZKYkquxzl7FMH0DcCEmjtclk0kcffRSKS8ek/+/l9/Xm0Ra1dHT3HusbeJJsFiXZLUobZdVVOakXTWf1DTxWi1lFkzN4EjyCouehsWaTdOujbzKNBiCmBeVds7i4WKa/vyl7vV59/PHH+vGPfxyMS8eFH9x4hbrcHnV2/2OFW9/Ak2i1EHRgiJ5ptFsffVPZaXZ9//e17F8EIGYFpdG676iQ1WpVVlaWEhISRnrZiBItjdZAKLB/EYBoFcj7tzkYN7zssst6XxMmTIi5QATEu579i5rbunSwoU33PV+nDrdn8C8EgCgSlH/qffDBB3r44Yf10UcfnbfJ4bZt24JxeQARYFFBrt4+9okOHG/V7g9O639qjuubcycbXRYABE1QQtGSJUv0ve99T0uXLpXZHJTBJwARJslm1ZqF07Ts8T3y+vza/k4DfW4AYkpQeormzJmjN954Ixj1RCx6ioBz6C8CEE3CvqP1c889p9dff12lpaWy2+29x6+99tqRXjpiEIqAf9hUfUyb3jwmr9+v/Nw0ghGAiBX2Ha137NihnTt36siRI73TZyaTKeJC0QsvvKB77rlHPp9P9957r7797W8bXRIQlXr6iw42tPU2XhOMAES7oIwUXXnllXr33Xd79yqKRB6PR/n5+Xr11VeVnp6uoqIivf766xo7duyQvp6RIuB8PQ+OPXC8Ve1dHi2/5nIarwFEnLAvyZ89e7Y++OCDYFwqZPbs2aNp06ZpwoQJSklJ0YIFC/TSSy8ZXRYQtXoar1MSrUpKsGj7Ow0s0wcQ1YISig4cOKDp06eroKBAs2fPVnFxsWbPnh2MS/fatWuXFi5cqNzcXJlMJm3duvWicxwOhyZPnqzExESVlJRoz549vZ9raGjQhAkTej+eMGGCTpw4EdQagXiTZLPK8fWrlZ5kU8qoBPYvAhDVgtIA8NxzzwXjMgNyuVwqKCjQ7bffrn/+53++6PObN29WRUWFNmzYoJKSElVWVmr+/Pl69913lZWVFfL6gHjVs7HjpjePqam1k/4iAFEraDtaHzx4UNu2bdNll10mu92ujo6OYFy614IFC3T//fdryZIl/X5+3bp1Wr58uZYtW6b8/Hxt2LBBSUlJeuyxxyRJubm5540MnThxQrm5uZe8X1dXl9ra2s57AejfooJcTR2fKknseA0gagUlFP3whz/Upk2b5HA4JEkWi0W33XZbMC49JG63WzU1NSotLe09ZjabVVpaqt27d0s61/d04MABnThxQk6nU3/60580f/78S17zgQceUHp6eu8rLy8v5N8HEK16+ovyc881MRKMAESjoISiqqoqPfHEExo1apQkady4cers7AzGpYekublZXq9X2dnZ5x3Pzs5WY2OjpHMPqv31r3+t6667ToWFhbrnnnsGXHm2atUqtba29r7q6+tD+j0A0e7CYPRuY7ue39dgcFUAMHRBCUUJCQny+Xy9S/JbWloi8nEfixYt0nvvvacjR47ojjvuGPBcu92utLQ0PfXUU5ozZ45uuOGGMFUJRK+eYHRldoq8Pr/2HG1htAhA1AhKcvn+97+vpUuXqrm5WT//+c917bXX6sc//nEwLj0kmZmZslgsampqOu94U1OTcnJyRnTt8vJyHTx4UNXV1SO6DhAvkmxWFU8ZK4vJpPea2plGAxA1hhWKLpxK+sY3vqGf//znuvfeezV69Gj993//t2699dagFDgUNptNRUVFqqqq6j3m8/lUVVWluXPnhq0OAOfQeA0gGg1rzexVV12le+65RytXrlRSUlLvsauuuiqoxfXldDp15MiR3o+PHj2q2tpaZWRkaNKkSaqoqFBZWZlmzZql2bNnq7KyUi6XS8uWLQtZTQD61zONdt/zdTrY0NbbX7S0eJLRpQHAJQ1rpOjll1/Wjh07dMUVV2jjxo1BLql/b731lmbOnKmZM2dKkioqKjRz5kytXr1akrR06VL96le/0urVq1VYWKja2lq9+OKLFzVfB8rhcCg/P1/FxcUj/h6AeNK38Toz1a5n9x5XszN8CzAAIFAjevbZk08+qZ/85CfKyspSZWWlrrnmmmDWFlF49hkwPB1uj779xFsym6Smti79/o4SZaYkGl0WAIN1uD36Q029aj5sUWe3V6fa3fryjPH615LLgrr5ayDv3yN+IGxHR4cefPBBrVu3Tl/60pe0du1aTZkyZSSXjEiEImD4mp2dWvrIG7KYpIxkmx5bNpsdr4EI1ezs1M+31enD0x3KSU+U9e9zSh6fX42tXQMeC+QcmaQWl1vtnV51uD2ymKXstFG6u/RKLZ45of/ihiGQ9++g/FW66aab1NbWpocffljbt2/XihUrtHr1aqWkpATj8oZyOBxyOBzyer1GlwJErcyURJV97jL952tH1dHtpb8ICIJmZ6ce2H5Ind3/WMQwnJBy4bH3mpxq6XCrw+3RocZ2WS3nTvJ4ffLLP+CxQM6xms0am2LT5eOSlZVi0ymnW1/+7HjdNG1kbS8jMayRog0bNqi6ulrV1dU6dOiQzGazpk+frjlz5qigoECbNm3SkSNH9Oyzz2rWrFmhqDvsGCkCRqbD7dF9z9fptMut9rPdcnz9aqbREJcuDDPDHYE58HG7znR0q9vjk/6+T2BP4DDJdF4A6fm4v3MuPJaRnCB7gkVjRtmUk26XtefaPr8a27oGPBbIORPHjFLJ5WP1L0UTQzpyHPLps7y8PJWUlGjOnDmaM2eOioqKenez7vHLX/5STz/9tA4cOBDo5SMSoQgYOfqLECs63B49/eZH2v7Ox8pKtQc0KnNhmBlKcOnvnASzZDGbNCkjWRNHJ/7jfgGGlAuPpdgTtPLLV8XM72ZYe4oupampSbm5uTEz7UQoAoKj2dmpWx99U9lpdvn80n+WzaK/CIYazsjNx21d+rC5Qx3dXvl8/oBGZS4MM8MdgbFazCqanBHykZZoF7KeotWrV+vmm29WUVHRoOdmZWXpz3/+cyCXj0j0FAHBlZmSqN/fUaLvPrVXbq9X/1NzXN+cO9noshBjAmkWvtTIzUB9MTaLSUl2i9JGWXVVTmpAozKEmcgV0EjR7bffrhdeeEE2m00LFy7UokWLdMMNN8hms4WyxojASBEQXPf+zz7t++iMuv0+bf7O3JgZqkdo9SzjfvODZh3/pHNIzcKhGLkh2ESPkE6f+Xw+/fWvf9Xzzz+v5557Th9//LFuvPFG3Xzzzfqnf/onZWRkjKj4SEUoAoKLaTT0p78Rnr5h55SzS6fau3Ta2a1unzcozcIEnNgW1p6iQ4cO9QakmpoazZ49W4sWLdKtt96qCROCt8+A0QhFQPA1OztV/ru3lTrKqrHJNq1ZOI03pRg3WP/OwY8vHuHpG3aSbBalJFo1NtkukxQ3zcIYPsMarU+dOtUbkK655hr98Ic/DNalDUcoAkJjU/UxbXrzmLx+v/Jz0whGMWCgKa7BVl6lJVouGuHpG3YSrRZGdRCQsG/eeOutt+qRRx7RuHHjlJmZqW984xv66le/GoxLG45GayC0FhXk6u1jn/Dg2Ch04WMaLjXF1bdhuad/Z0p2ar/9O4k2KyM8MExQRopmzJihd955RwcPHtTXvvY1zZs3TyaTSQ8//HAwaowIjBQBocPGjpGvv2mvw41OeX1+ObvOPaZhKFNc9O8g3MI+UpSQkCC/36/HH39cq1at0te//vUhLdsHAElKslm1ZuE0LXu8Wu2dHv3qxXf14C0FRpcVt/oLQHuPtcpsNqm98+/HvD6ZTX4l2ay6fFyKslJsTHEh6gXlv9Y777xTV199tc6cOaOf/vSnkiSXyxWMSwOIE0k2q74yI0fPVB/XB6dcanZ2MloUBn2nwDxe3yUDkN0iJdqsuv7KzHPHfP7eZ1XdWjKJ8IOYMKz/iuvr65WXl9f78be//W3dcsstslqtSk5O1pEjRzRnzpygFQkgPtxSlKcXDzQpwWLS939fyzL9ELgwBB0/06n6lrPy+v3q9vovGYBaOrr1668VKC8j2eDvAAidYfUUJScn65577tHKlSuVlJQUiroiDj1FQHiwTD/4eqbDnF3d5/UBub0++f1+2S0mjU62afr4NAIQYk7Ie4pefvll/eAHP9B//dd/6Re/+IVuu+224VwmKrD6DAivzJRELbl6gja9eUzN7V2sRhuGCx9W+l6TU50er0473ef1AeWm2SWJFV/A341o9dmTTz6pn/zkJ8rKylJlZaWuueaaYNYWURgpAsKH1WiB6zstVv/J2fMeVpqRnKBRNqumZqXQB4S4E9bNGzs6OvTggw9q3bp1+tKXvqS1a9dqypQpI7lkRCIUAeHV4fbo20+8pQSLSd1eP/1F/egbhD483dHbG2SSlGS3yGYx66qcVHZ3RlwL+5L8m266SW1tbXr44Ye1fft2rVixQqtXr1ZKSkowLg8gDiXZrHro1kJ996m9cnu9+p+a4/rm3MlGlxUR6ltc+sHmfer2etXicqu906suj1d2i0ljkm0qnDiaJfHAMAzrt2XDhg2qrq5WdXW1Dh06JLPZrOnTp+u73/2uCgoKtGnTJuXn5+vZZ5/VrFmzgl0zgDiRmZKoT2Ula399q7a/0xDXb/J9R4Ve/6BFnR6fPF6fxqbYdPm4ZOWm2ekNAkZoWNNneXl5Kikp0Zw5czRnzhwVFRVp1KhR553zy1/+Uk8//bQOHDgQtGKNxPQZYIye1WhjkhN03dSsuGu67mma/t0bx9Tt9cnZ5ZXNKvn9UsmUsSq5fGxch0VgMIY9ELavpqYm5ebmxsyqLUIRYJxN1cf0v++dUnKiNW6W6Pcsoz962qUPmzvU7fUpwWLS5MwUXZ6ZzIgQMERh7ynqT3Z2tv785z+H6vIA4siiglzVfvSJzpx1677n62I6GPX0C51ydsrt8ems26sku0WjrQn6esllrBoDQiig36yf/exnAV183rx5AZ0fidinCDBeks2qwsvGaNObx9TYGpt7F/WMDO16v1mdHp/M8isjxa6SyRk0TQNhEtBvWIhm2iJaeXm5ysvLe4ffABhjUUGu3j72iVrPdmvvsU+0sCA3JkJCTxjae+yMOj1emUx+JVpN+vyns/R//ukzTJEBYRSynqJYQ08RYLwOt0c/21Ynp9uja64YF/WjRfUtLt2yYbckySS/RtmsKpo0hn4hIIgioqcIAIItyWZV/oR0PVtzXHuOtkTtaFHfqbJRdovOdnn0xSuzCEOAwaLvrwmAuGazmiVJH5xyRl1vUc9eQ0+8/qE63Oemyrq6fXr2//k8D18FIoDZ6AIAIBCLCnI1dXyqctITtffYJ+pwe4wuaUg63B7936379ZtX3pdJUmKCRddekaXt3/8CgQiIEIQiAFElyXZur6LRiQlydXn0/L4Go0saVLOzU8se36M3/nZaVotJkknPfHeufvW1QqbLgAhCKAIQdXqW6MuviB8tanZ26tZH39QnLrdMJpOmZKZo03fmEIaACEQoAhCVFhXkKsVujdjRog63R0/uPqqlj+xWZopNXr/0nWs/pcduKyYQARGKUAQgKkX6aNEfaur1m6ojMklqdrq1+Ttz9M25k6NytRwQLwhFAKJWJI4W9YwQPf7XoxozyirJpN/fUcLoEBAFCEWDcDgcys/PV3FxsdGlALhApI0Wdbg9uu/5Ov3na0eVYDbLZDLTPwREEXa0HiJ2tAYiU6Tsct0TiOoa2uT3SamjrFr/rzMJRIDBAnn/ZqQIQFTr2eX64zPnnipvhL6ByCSTPjsxjYZqIAoRigBEPZvVrPHpiTrQ0GrIFNq2fQ06/HG7TDJpWm6qVi+cRkM1EIUIRQCinpEN1x1uj6qPnpbPL03NTiEQAVGMUAQg6hnVcN0zbfZuk1MWs0nFUzIIREAUIxQBiAmLCnI1OsmmyWOT9VJdU1ju2Xfa7KqcFC0syA3LfQGEBqEIQExIsll1941X6MQnZ/WFK8aG/H7Nzk5t2XtCWWl2+oiAGEEoAhAzXnu/WRNGj1Lly++HdAqtw+3R939fq8QEszq6vAQiIEYQigDEjPnTcvTRaZfOnHWHtOH6DzX1ajvbrbNur35zayGBCIgRhCIAMSMcDdcdbo+2v9Mon9+vyzOT2YsIiCGEIgAxJdQN19v2NWh0klVpoxL0wy9NDfr1ARiHUAQgpoSy4brD7dHbH32iBItFS2ZOYJQIiDFxF4qWLFmiMWPG6JZbbjG6FAAhEqqG6237GuTs8ijFbmH5PRCD4i4U3XXXXXryySeNLgNACM2flqMTZ85qwphRQZtC6xklMplMmjlpDM3VQAyKu1A0b948paamGl0GgBAKxRQao0RA7IuoULRr1y4tXLhQubm5MplM2rp160XnOBwOTZ48WYmJiSopKdGePXvCXyiAiPfKoSa1d3pUdejkiK/FKBEQHyIqFLlcLhUUFMjhcPT7+c2bN6uiokJr1qzR3r17VVBQoPnz5+vkyX/80SssLNT06dMvejU0hPchkQCMZpLJFJwrMUoExIeI+ufOggULtGDBgkt+ft26dVq+fLmWLVsmSdqwYYO2b9+uxx57TCtXrpQk1dbWBqWWrq4udXV19X7c1tYWlOsCCI9FBbkySfLr3EjPcEd3GCUC4kdEjRQNxO12q6amRqWlpb3HzGazSktLtXv37qDf74EHHlB6enrvKy8vL+j3ABA6STarbFazXJ2eETVbM0oExI+oCUXNzc3yer3Kzs4+73h2drYaGxuHfJ3S0lJ99atf1R//+EdNnDjxkoFq1apVam1t7X3V19ePqH4A4XfNFZk62uwaUbO12+PTx62dmpabzigREOPi7jf8lVdeGdJ5drtddrs9xNUACKXX3m/WlMxk/e/7p7V45oRhXcNmNWlSRpJs1qj5NySAYYqa3/LMzExZLBY1NZ0/DN7U1KScnJyQ3dfhcCg/P1/FxcUhuweA0Jg/LUcpiVZ1erzD2sSx52vmfmosU2dAHIiaUGSz2VRUVKSqqqreYz6fT1VVVZo7d27I7lteXq6DBw+quro6ZPcAEBoj7Svatq9Buz9o6b0WgNgWUb/lTqdTR44c6f346NGjqq2tVUZGhiZNmqSKigqVlZVp1qxZmj17tiorK+VyuXpXowHAha65IlOVL7+vm2cGNtLTs+rM6/OHqDIAkSaiQtFbb72l6667rvfjiooKSVJZWZk2btyopUuX6tSpU1q9erUaGxtVWFioF1988aLm62ByOBxyOBzyer0huweA0BluX9GOukZNHpusE2fOMnUGxAmT3+/nn0FD0NbWpvT0dLW2tiotLc3ocgAMUYfbo+f3Ncivc3sXDXUarNnZqcqX39fdN16hzJTE0BYJIGQCef+Omp4iABiO4fYV9R1hAhAfCEWDYPUZEP0C3a+ow+1Rl8erlESrbpoWuul5AJGFUDQIVp8B0S/QUR9WnQHxiVAEIOYFvl+RX0F6liyAKEIoAhDzAukrYsNGIH4RigDEhfnTcjQ2xT5oj9COuka5Or2yWy1MnQFxhlA0CBqtgdjh1+A7kATjIbIAohP7FA0R+xQB0W3L28fV4nRrbIp9wE0ch3oegOjAPkUAcIGhTp8N9TwAsYdQBCBuDDZ91uH2aEddo26alk0/ERCHCEWDoKcIiA076hrV4nQPuPpsKOcAiF30FA0RPUVAdOtwn1uOP9AoEM87A2IPPUUAcIEk27lHduyoa7zkBo487wyIb4QiAHFjsOkxmqyB+EYoAhA3hhJ6hrKXEYDYRCgCEFcGCj00WgPxjVAEIG4wfQZgIISiQbAkH4gdA4Ue9igCwJL8IWJJPhDbeLwHEJtYkg8Al9Dh9mjL28cvWpbP1BkAQhGAuHKpvqIkm1WLZ05g6gyIY4QiAHHlUiNClxpBAhA/CEUA4sqlRoRYjg+AUAQAoqcIAKFoUCzJB2LLpabJ6CkCwJL8IWJJPhAbWHoPxBeW5APAJfQ3TUaTNQCJUAQgzvQ3TUaTNQCJUAQANFkDkCTRUQgg7vWMHgGIb4wUAYg79BAB6A+hCEDcubCHiJAEQCIUAYhDF/YQ0WgNQCIUAYhDF65Ao9EagESjNQDQaA1AEiNFg+IxHwAAxAce8zFEPOYDiB0dbo921DVq/rQcnnUGxDge8wEAA6CxGkB/CEUA4k7fxmqW4wPoQSgCEHf6rj5j1AhAD0IRgLjGcnwAPegwBBDXWI4PoAcjRQAAACIUAQAASCIUAQAASCIUAQAASCIUAYhTPfsTNTs72acIgCRCEYA41bM/UeXL77NPEQBJcRaK6uvrNW/ePOXn52vGjBl65plnjC4JgEF69ie6+8Yr2KcIgKQ4eyDsxx9/rKamJhUWFqqxsVFFRUV67733lJycPOjX8kBYAACiTyDv33G1eeP48eM1fvx4SVJOTo4yMzPV0tIypFAEAABiW0RNn+3atUsLFy5Ubm6uTCaTtm7detE5DodDkydPVmJiokpKSrRnz55h3aumpkZer1d5eXkjrBoAAMSCiApFLpdLBQUFcjgc/X5+8+bNqqio0Jo1a7R3714VFBRo/vz5OnnyZO85hYWFmj59+kWvhoaG3nNaWlr0rW99S48++mjIvycAABAdIranyGQyacuWLVq8eHHvsZKSEhUXF2v9+vWSJJ/Pp7y8PK1YsUIrV64c0nW7urp04403avny5frmN7854HldXV29H7e1tSkvL4+eIgAAokggPUURNVI0ELfbrZqaGpWWlvYeM5vNKi0t1e7du4d0Db/fr9tuu03XX3/9gIFIkh544AGlp6f3vphmAwAgtkVNKGpubpbX61V29vnLZrOzs9XY2Dika/z1r3/V5s2btXXrVhUWFqqwsFD79+/v99xVq1aptbW191VfXz/i7wEAAESuuFp99oUvfEE+n29I59rtdtnt9hBXBAAAIkXUjBRlZmbKYrGoqen8XWebmpqUk5MTsvs6HA7l5+eruLg4ZPcAAADGi5pQZLPZVFRUpKqqqt5jPp9PVVVVmjt3bsjuW15eroMHD6q6ujpk9wAAAMaLqOkzp9OpI0eO9H589OhR1dbWKiMjQ5MmTVJFRYXKyso0a9YszZ49W5WVlXK5XFq2bJmBVQMAgFgQUaHorbfe0nXXXdf7cUVFhSSprKxMGzdu1NKlS3Xq1CmtXr1ajY2NKiws1IsvvnhR83UwORwOORwOeb3ekN0DQPh1uD3atu+EJJMWFeQqyRZRfw4BGCBi9ymKNDz7DIgtW94+rp2HT8lkkuZNzdLimROMLglACPDsMwAYxPxpOXJ7zq1GvWla6EabAUQPQhGAuJRks2pp8SSjywAQQaJm9ZlRWJIPAEB8oKdoiOgpAgAg+sTks88AAABCiVAEAAAgQtGg6CkCACA+0FM0RPQUAQAQfegpAgAACBChCAAAQIQiAAAASYSiQdFoDQBAfKDReohotAYAIPrQaA0AABAgQhEAAIAIRQAAAJIIRQAAAJIIRYNi9RkAAPGB1WdDxOozAACiD6vPAAAAAkQoAgAAEKEIAABAEqEIAABAEqEIAABAEqFoUCzJBwAgPrAkf4hYkg8AQPRhST4AAECACEUA4laH26Mtbx9Xh9tjdCkAIgChCEDc2rbvhHYePqXn9zUYXQqACEAoAhDHTDKZjK4BQKSwGl0AABhlUUGuEq0W3TQt2+hSAEQAQhGAuJVks2rxzAlGlwEgQjB9BgAAIEIRAACAJEIRAACAJELRoHjMBwAA8YHHfAwRj/kAACD68JgPAACAABGKAAAARCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQJFmNLiBa9Oxx2dbWZnAlAABgqHret4eyVzWhaIja29slSXl5eQZXAgAAAtXe3q709PQBz+ExH0Pk8/nU0NCg1NRUmUymoF67ra1NeXl5qq+v5xEiIcTPOTz4OYcPP+vw4OccHqH6Ofv9frW3tys3N1dm88BdQ4wUDZHZbNbEiRNDeo+0tDR+4cKAn3N48HMOH37W4cHPOTxC8XMebISoB43WAAAAIhQBAABIIhRFBLvdrjVr1shutxtdSkzj5xwe/JzDh591ePBzDo9I+DnTaA0AACBGigAAACQRigAAACQRigAAACQRigAAACQRiiLOL37xC33uc59TUlKSRo8ebXQ5McXhcGjy5MlKTExUSUmJ9uzZY3RJMWXXrl1auHChcnNzZTKZtHXrVqNLikkPPPCAiouLlZqaqqysLC1evFjvvvuu0WXFnN/+9reaMWNG70aCc+fO1Z/+9Cejy4p5Dz74oEwmk+6++25D7k8oijBut1tf/epXdeeddxpdSkzZvHmzKioqtGbNGu3du1cFBQWaP3++Tp48aXRpMcPlcqmgoEAOh8PoUmLaX/7yF5WXl+uNN97Qyy+/rO7ubt10001yuVxGlxZTJk6cqAcffFA1NTV66623dP311+vmm29WXV2d0aXFrOrqaj3yyCOaMWOGYTWwJD9Cbdy4UXfffbfOnDljdCkxoaSkRMXFxVq/fr2kc8+yy8vL04oVK7Ry5UqDq4s9JpNJW7Zs0eLFi40uJeadOnVKWVlZ+stf/qJrr73W6HJiWkZGhtauXat/+7d/M7qUmON0OnX11Vfr3//933X//fersLBQlZWVYa+DkSLEPLfbrZqaGpWWlvYeM5vNKi0t1e7duw2sDBi51tZWSefesBEaXq9XmzZtksvl0ty5c40uJyaVl5frK1/5ynl/p43AA2ER85qbm+X1epWdnX3e8ezsbB0+fNigqoCR8/l8uvvuu/X5z39e06dPN7qcmLN//37NnTtXnZ2dSklJ0ZYtW5Sfn290WTFn06ZN2rt3r6qrq40uhZGicFi5cqVMJtOAL96cAQSqvLxcBw4c0KZNm4wuJSZNnTpVtbW1evPNN3XnnXeqrKxMBw8eNLqsmFJfX6+77rpLv/vd75SYmGh0OYwUhcM999yj2267bcBzLr/88vAUE4cyMzNlsVjU1NR03vGmpibl5OQYVBUwMt/73vf0wgsvaNeuXZo4caLR5cQkm82mT3/605KkoqIiVVdX6ze/+Y0eeeQRgyuLHTU1NTp58qSuvvrq3mNer1e7du3S+vXr1dXVJYvFErZ6CEVhMG7cOI0bN87oMuKWzWZTUVGRqqqqeht/fT6fqqqq9L3vfc/Y4oAA+f1+rVixQlu2bNHOnTs1ZcoUo0uKGz6fT11dXUaXEVNuuOEG7d+//7xjy5Yt01VXXaV77703rIFIIhRFnGPHjqmlpUXHjh2T1+tVbW2tJOnTn/60UlJSjC0uilVUVKisrEyzZs3S7NmzVVlZKZfLpWXLlhldWsxwOp06cuRI78dHjx5VbW2tMjIyNGnSJAMriy3l5eV6+umn9dxzzyk1NVWNjY2SpPT0dI0aNcrg6mLHqlWrtGDBAk2aNEnt7e16+umntXPnTu3YscPo0mJKamrqRf1wycnJGjt2rDF9cn5ElLKyMr+ki16vvvqq0aVFvYcfftg/adIkv81m88+ePdv/xhtvGF1STHn11Vf7/W+3rKzM6NJiSn8/Y0n+xx9/3OjSYsrtt9/uv+yyy/w2m80/btw4/w033OB/6aWXjC4rLnzxi1/033XXXYbcm32KAAAAxOozAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAAAASYQiAHHs1KlTysnJ0S9/+cveY6+//rpsNpuqqqoMrAyAEXggLIC49sc//lGLFy/W66+/rqlTp6qwsFA333yz1q1bZ3RpAMKMUAQg7pWXl+uVV17RrFmztH//flVXV8tutxtdFoAwIxQBiHtnz57V9OnTVV9fr5qaGn32s581uiQABqCnCEDc++CDD9TQ0CCfz6cPP/zQ6HIAGISRIgBxze12a/bs2SosLNTUqVNVWVmp/fv3Kysry+jSAIQZoQhAXPvRj36kP/zhD9q3b59SUlL0xS9+Uenp6XrhhReMLg1AmDF9BiBu7dy5U5WVlXrqqaeUlpYms9msp556Sq+99pp++9vfGl0egDBjpAgAAECMFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEgiFAEAAEiS/n+4/uXim91rlAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sample.x[:,0], np.abs(y_emu[:,0]/sample.y[:,0]-1.), s=0.1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('$\\\\left|y_s/y_\\\\mathrm{emu}-1\\\\right|$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pbj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
